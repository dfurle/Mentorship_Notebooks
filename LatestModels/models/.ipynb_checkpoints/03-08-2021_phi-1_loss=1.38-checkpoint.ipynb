{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te6rdZgT5yAW"
   },
   "source": [
    "# Copy of Previous RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdsGeayZ523e"
   },
   "source": [
    "### Reminders:\n",
    "\n",
    "Read up on some of these:\n",
    "- https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/\n",
    "- https://fairyonice.github.io/Stateful-LSTM-model-training-in-Keras.html \n",
    "- https://github.com/keras-team/keras/issues/5714\n",
    "- https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/\n",
    "\n",
    "###Shuffle Data!!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ro1oh9-25xM9",
    "outputId": "e2638721-dec3-4b6c-9db0-df28d7fce705"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7yOaxkJ58hh"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5Lupm0J6Hre"
   },
   "source": [
    "## Do Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gE8NHB9v6IDc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "from math import isnan\n",
    "from scipy.stats import norm\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yhg_bSj36CSt"
   },
   "source": [
    "## Obtain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1LMf25vB5_vs"
   },
   "outputs": [],
   "source": [
    "# read data from drive\n",
    "# csv_train = pandas.read_csv(\"drive/MyDrive/first_10k.csv\")\n",
    "csv_train = pandas.read_csv(\"first_10k.csv\")\n",
    "# csv_train = pandas.read_csv(\"drive/MyDrive/FDC_tracks.csv\")\n",
    "unparsed_train = np.array(csv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7L54wTFh-NGU"
   },
   "source": [
    "## Ragged Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoN7P86yCif6",
    "outputId": "b9ad9880-a607-4ac8-dd65-3e3a802f4a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.588573718740314, 47.716949659038654, 47.92074125234375, 0.0433333333333333, 96.0, 24.0, 343.50521373311966, 274.8641357421875, 3.24600255369344e-07, 137.76808719278492]\n",
      "[-47.69482374702719, -47.64816097490714, -47.78196688638672, 0.0100725857504721, 1.0, 1.0, 176.8656847042481, -77.76896667480467, 7.068405941829982e-10, 0.2999999999999999]\n",
      "[53.93938010927168, 182.16740477086037, 20.384216393930128, 80.4857546970404]\n",
      "[-59.97950523099952, -113.91363367061092, -21.351611455494343, -101.41199494730319]\n"
     ]
    }
   ],
   "source": [
    "_max = [-1000 for i in range(10)]\n",
    "_min = [1000 for i in range(10)]\n",
    "for index,event in enumerate(unparsed_train):\n",
    "  lower = 67\n",
    "  for upper in range(lower+14, event.shape[0]+1, 14):\n",
    "    d = event[lower:upper]\n",
    "    d = np.append(d[:2],d[6:])\n",
    "    for a in range(len(d)):\n",
    "      if d[a] > _max[a]:\n",
    "        _max[a] = d[a]\n",
    "      if d[a] < _min[a]:\n",
    "        _min[a] = d[a]\n",
    "    lower = upper\n",
    "print(_max)\n",
    "print(_min)\n",
    "\n",
    "_TOF_max = [-1000 for i in range(4)]\n",
    "_TOF_min = [1000 for i in range(4)]\n",
    "for index,event in enumerate(unparsed_train):\n",
    "  TOF = event[59:67]\n",
    "  # print(TOF)\n",
    "  for a in range(4):\n",
    "    if TOF[a*2] > _TOF_max[a]:\n",
    "      _TOF_max[a] = TOF[a*2]\n",
    "    if TOF[a*2] < _TOF_min[a]:\n",
    "      _TOF_min[a] = TOF[a*2]\n",
    "print(_TOF_max)\n",
    "print(_TOF_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOfDY5F8yJyl"
   },
   "source": [
    "After trying out many different possibilities, I have found making a RaggedTensor is the way to make variable timesteps.\n",
    "\n",
    "Once you create a RaggedTensor ONLY FOR X DATA, you need to also add:\n",
    "\n",
    "ragged=True\n",
    "\n",
    "to the keras.Inputs() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BfACUWvW-NGd"
   },
   "outputs": [],
   "source": [
    "def ragged_parser(unparsed):\n",
    "  global _min, _max\n",
    "  x_final = []\n",
    "  y_final = []\n",
    "  invCov_final = []\n",
    "  cov_final = []\n",
    "  for event in unparsed:\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    nEvent = event[0]     # all the data split into neat little arrays...\n",
    "    state = event[1:6]\n",
    "    coVar = event[6:31]\n",
    "    invCoVar = event[31:56]\n",
    "    goodnessOfFit = event[56:59]\n",
    "    TOF = event[59:67]\n",
    "\n",
    "    if goodnessOfFit[2] > 0.1:   # Cutting if rms is too high\n",
    "      continue\n",
    "    hits = []\n",
    "    lower = 67\n",
    "    for upper in range(lower+14, event.shape[0]+1, 14): # to flip just go from end to 67 by -14 steps?\n",
    "\n",
    "      # hasNAN = False\n",
    "      # for val in event[lower:upper]:\n",
    "      #   if isnan(val):\n",
    "      #     hasNAN = True\n",
    "      # if not hasNAN:\n",
    "\n",
    "      if not isnan(event[lower]):            # Check if we are done with hits, because data is cut short, the rest will be nan\n",
    "        hit_data = event[lower:upper]                      # retrieving the hit\n",
    "        hit_data = np.append(hit_data[:2],hit_data[6:])    # cutting out the sin and cos data\n",
    "        for z in range(len(hit_data)):\n",
    "          hit_data[z] = (hit_data[z] - _min[z]) / (_max[z] - _min[z])    # we need to normalize the data; this can be moved to a lambda layer in the network if needed.\n",
    "        for i_TOF in range(4):\n",
    "          TOF[i_TOF*2] = (TOF[i_TOF*2] - _TOF_min[i_TOF]) / (_TOF_max[i_TOF] - _TOF_min[i_TOF])\n",
    "        hit_data = np.append(hit_data,TOF)\n",
    "        hits.append(np.ndarray.tolist(hit_data))       # we want it as a list to convert to RaggedTensor later; last time I checked it didnt work with array.\n",
    "      lower = upper\n",
    "    for i in range(len(hits)):   # this could be simplified to just: \"x = hits\" if im not mistaken...\n",
    "      x.append(hits[i])          # however we might need to add y.append(hits[i+1]) for later testing so leaving it like this for now...\n",
    "    y = np.ndarray.tolist(state)   # technically not needed, can be removed later... at first I thought i need to pass RaggedTensor labels, but that is not the case.\n",
    "    x_final.append(x)          # want x_final to be shape (event, hit, 10) as a list\n",
    "#     y_final.append(y)          # want y_final to be shape (event, 5)       as a np.array\n",
    "    y_final.append(y[1])          # want y_final to be shape (event, 5)       as a np.array\n",
    "    invCov_final.append(invCoVar[:])  # want other_f to be shape (event, 25)      as a np.array\n",
    "    cov_final.append(coVar[:])\n",
    "  x_final = tf.ragged.constant(x_final)   # convert list to RaggedTensor because timesteps (number of hits) are variable between events\n",
    "  y_final = np.array(y_final)\n",
    "  invCov_final = np.array(invCov_final)\n",
    "  cov_final = np.array(cov_final)\n",
    "  return [x_final, invCov_final, cov_final, y_final], y_final   # with the custom loss the x_train (input) needs to be a list of [inputs, inverseCovariance, labels]\n",
    "  # return [x_final, invCov_final], y_final   # with the custom loss the x_train (input) needs to be a list of [inputs, inverseCovariance, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7H0PK6Q-NGg",
    "outputId": "6fcb6671-f32c-402a-c1a3-8489231a8d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--==Types==--\n",
      "--x_train:--\n",
      "\n",
      "  -> input_data: x_train[0]\n",
      "  -> type expected: RaggedTensor\n",
      " <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "\n",
      "  -> invCov: x_train[1]\n",
      "  -> type expected: np.array\n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "  -> y_train: x_train[2]\n",
      "  -> type expected: np.array\n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "--y_train:--\n",
      "\n",
      "  -> y_train: y_train\n",
      "  -> type expected: np.array\n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "--==Shapes==--\n",
      "--x_train:--  \n",
      "num of events: 7729\n",
      "\n",
      "  RaggedTensor | Input:  shape = (7729, 18, 18)\n",
      "  np.array     | InvCov: shape = (7729, 25)\n",
      "  np.array     | Labels: shape = (7729, 25)\n",
      "\n",
      "--x_train:--\n",
      "  np.array     | Labels: shape = (7729,)\n",
      "x_train : <tf.RaggedTensor [[0.7692640423774719, 0.765606164932251, 0.22407019138336182, 0.2642019987106323, 0.49473685026168823, 0.9130434989929199, 0.9742012023925781, 0.8189674615859985, 0.006027945317327976, 0.006027945317327976, 0.5265106558799744, 0.0, 0.4158459007740021, 1.0, 0.511589527130127, 0.0, 0.5575219988822937, 0.0], [0.6926482319831848, 0.5690751671791077, 0.3645309507846832, 0.05952613055706024, 0.2631579041481018, 0.8695651888847351, 0.9611853361129761, 0.28649309277534485, 0.033259935677051544, 0.033259935677051544, 0.5311324596405029, 0.0, 0.3861425220966339, 1.0, 0.5238472819328308, 0.0, 0.5605869889259338, 0.0], [0.23875504732131958, 0.24075621366500854, 0.7672280669212341, 0.10457572340965271, 0.5052631497383118, 0.782608687877655, 0.9352953433990479, 0.504021406173706, 0.018304066732525826, 0.018304066732525826, 0.5311729907989502, 0.0, 0.38604220747947693, 1.0, 0.5241410136222839, 0.0, 0.5606038570404053, 0.0], [0.33787238597869873, 0.4484703540802002, 0.6097946166992188, 0.07363839447498322, 0.7157894968986511, 0.739130437374115, 0.7676599621772766, 0.33562812209129333, 0.02666318602859974, 0.02666318602859974, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241480469703674, 0.0, 0.5606039762496948, 0.0], [0.5710769891738892, 0.6744455695152283, 0.37305063009262085, 0.288280189037323, 0.7052631378173828, 0.695652186870575, 0.7548211812973022, 0.7309820652008057, 0.005347346421331167, 0.005347346421331167, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.733315110206604, 0.7239073514938354, 0.263613760471344, 0.041055768728256226, 0.4842105209827423, 0.6521739363670349, 0.7418311238288879, 0.5430606007575989, 0.048400089144706726, 0.048400089144706726, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.6543219089508057, 0.5472460389137268, 0.39544129371643066, 0.12399385124444962, 0.2947368323802948, 0.6086956262588501, 0.728915810585022, 0.5731130242347717, 0.015151274390518665, 0.015151274390518665, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.42824169993400574, 0.3272317349910736, 0.6255077123641968, 0.04272006079554558, 0.3052631616592407, 0.5652173757553101, 0.7160916924476624, 0.30231329798698425, 0.046525269746780396, 0.046525269746780396, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.2750035524368286, 0.28259047865867615, 0.7278001308441162, 0.024007415398955345, 0.5157894492149353, 0.52173912525177, 0.703081488609314, 0.3300199508666992, 0.08132698386907578, 0.08132698386907578, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.3927527666091919, 0.47597992420196533, 0.5672175288200378, 0.08297774195671082, 0.6631578803062439, 0.47826087474823, 0.4162442684173584, 0.5024588704109192, 0.023499751463532448, 0.023499751463532448, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.567786455154419, 0.6398308277130127, 0.392142653465271, 0.030097603797912598, 0.6421052813529968, 0.43478259444236755, 0.40303486585617065, 0.2945617437362671, 0.06557145714759827, 0.06557145714759827, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.6758876442909241, 0.6613656878471375, 0.3252999782562256, 0.05598178505897522, 0.4736842215061188, 0.3913043439388275, 0.39034584164619446, 0.45713284611701965, 0.035419683903455734, 0.035419683903455734, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.6067799925804138, 0.5218054056167603, 0.433348685503006, 0.06648389250040054, 0.3368421196937561, 0.3478260934352875, 0.3770085275173187, 0.44806209206581116, 0.029668668285012245, 0.029668668285012245, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.33219149708747864, 0.3447727859020233, 0.6660985350608826, 0.02286168746650219, 0.5263158082962036, 0.260869562625885, 0.35123491287231445, 0.42745885252952576, 0.085147425532341, 0.085147425532341, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.436598539352417, 0.4929949641227722, 0.5362541675567627, 0.03817495331168175, 0.6105263233184814, 0.21739129722118378, 0.0648939236998558, 0.2867984175682068, 0.052010804414749146, 0.052010804414749146, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.6153600811958313, 0.6007120013237, 0.38774821162223816, 0.04457264766097069, 0.4736842215061188, 0.1304347813129425, 0.038748566061258316, 0.4948866367340088, 0.04459531232714653, 0.04459531232714653, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.45056793093681335, 0.40904945135116577, 0.5723205208778381, 0.04106782376766205, 0.42105263471603394, 0.043478261679410934, 0.012867040000855923, 0.33683282136917114, 0.048385992646217346, 0.048385992646217346, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0], [0.3925012946128845, 0.4053120017051697, 0.6041624546051025, 0.032487500458955765, 0.5263158082962036, 0.0, 0.00017478904919698834, 0.65003901720047, 0.060900986194610596, 0.060900986194610596, 0.5311733484268188, 0.0, 0.3860418498516083, 1.0, 0.5241482257843018, 0.0, 0.5606039762496948, 0.0]]>\n",
      "y_train : -1.959486255086148\n"
     ]
    }
   ],
   "source": [
    "# split = 450000\n",
    "# split = 3\n",
    "# split = int(unparsed_train.shape[0]*0.90)\n",
    "x_train, y_train = ragged_parser(unparsed_train[0:8300]) # shuffle data before taking\n",
    "x_test, y_test = ragged_parser(unparsed_train[8300:])\n",
    "# x_train, y_train = ragged_parser(unparsed_train[:split])\n",
    "# x_test , y_test  = ragged_parser(unparsed_train[split:split+100])\n",
    "\n",
    "print(\"--==Types==--\")\n",
    "print(\"--x_train:--\")\n",
    "print(\"\\n  -> input_data: x_train[0]\\n  -> type expected: RaggedTensor\\n \"+str(type(x_train[0])))\n",
    "print(\"\\n  -> invCov: x_train[1]\\n  -> type expected: np.array\\n \"+str(type(x_train[1])))\n",
    "print(\"\\n  -> y_train: x_train[2]\\n  -> type expected: np.array\\n \"+str(type(x_train[2])))\n",
    "print(\"\\n--y_train:--\")\n",
    "print(\"\\n  -> y_train: y_train\\n  -> type expected: np.array\\n \"+str(type(y_train)))\n",
    "\n",
    "print(\"\\n\\n--==Shapes==--\")\n",
    "print(\"--x_train:--  \\nnum of events: \" + str(x_train[0].shape[0]))\n",
    "print(\"\\n  RaggedTensor | Input:  shape = \" + \"(\" + str(x_train[0].shape[0]) + \", \"+ str(x_train[0][0].shape[0]) + \", \"+ str(x_train[0][0][0].shape[0]) + \")\")\n",
    "print(\"  np.array     | InvCov: shape = \" + str(x_train[1].shape))\n",
    "print(\"  np.array     | Labels: shape = \" + str(x_train[2].shape))\n",
    "print(\"\\n--x_train:--\")\n",
    "print(\"  np.array     | Labels: shape = \" + str(y_train.shape))\n",
    "\n",
    "print(\"x_train : \" + str(x_train[0][0]))\n",
    "print(\"y_train : \" + str(y_train[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMvnihIl6ail"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdreWH016c08"
   },
   "source": [
    "## Defining Models\n",
    "\n",
    "- model\n",
    "  - Very basic testing RNN model\n",
    "  - Output every timestep\n",
    "\n",
    "- model_timeless\n",
    "  - Very basic testing RNN model\n",
    "  - Output only at the end\n",
    "\n",
    "- RNNTime\n",
    "  - Advanced\n",
    "  - Time distributed, output every timestep\n",
    "\n",
    "- RNNTimeless\n",
    "  - Advanced\n",
    "  - Only output at final layer\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e8qCwtNw6bFk"
   },
   "outputs": [],
   "source": [
    "def model(x):\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='input_lstm1', return_sequences=True)(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(32, activation='relu'), name=\"TD1-Dense\")(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(14, activation='linear'), name=\"output-Dense\")(x)\n",
    "  return x\n",
    "def model_timeless(x):\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='input_lstm1', return_sequences=False)(x)\n",
    "  x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dense(5, activation='relu', name=\"output-Dense\")(x)\n",
    "  return x\n",
    "\n",
    "def RNNTime(x):\n",
    "  x = keras.layers.LSTM(128,activation=\"tanh\", name='input_lstm1', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm2', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(32,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(32, activation='relu'), name=\"TD1-Dense\")(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(5, activation='linear'), name=\"output-Dense\")(x)\n",
    "  return x\n",
    "\n",
    "def RNNTimeless(x):\n",
    "  x = keras.layers.LSTM(128,activation=\"tanh\", name='input_lstm1', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm2', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=False)(x)\n",
    "  x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dense(1, activation='linear', name=\"output-Dense\")(x)\n",
    "  # x = keras.layers.Dense(5, activation='linear', name=\"output-Dense\")(x)\n",
    "  # x = keras.layers.lambda(# normalize)\n",
    "  return x\n",
    "\n",
    "\n",
    "# def RNNTimeless(x):\n",
    "#   x = keras.layers.LSTM(128,activation=\"tanh\", name='input_lstm1', stateful=False, return_sequences=True)(x)\n",
    "#   x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm2', stateful=False, return_sequences=True)(x)\n",
    "#   x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=False)(x)\n",
    "#   x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "#   x = keras.layers.Dense(5, activation='linear', name=\"output-Dense\")(x)\n",
    "#   # x = keras.layers.lambda(# normalize)\n",
    "#   return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gtf37tFTB5HU"
   },
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOZIj6R8u0VG"
   },
   "source": [
    "### V1 Originial, unedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v8iA9da3HLBs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_loss\n",
    "\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = x_train[2][0]\n",
    "# y_test = model.predict([x_train[0][0:1],x_train[1][0:1],x_train[2][0:1]])\n",
    "# y_test = np.squeeze(y_test)\n",
    "# inconv_test = x_train[1][0]\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXxfMKTqTvBC"
   },
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZX3nAlhgTu4h"
   },
   "outputs": [],
   "source": [
    "def customMetric(y_true, y_pred, cov, id=0):\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  cov = K.reshape(cov, (batch_size, 5,5)) # cov  shape is now (batch, 5,5)\n",
    "  # cov = tf.transpose(cov, perm=[0,2,1])     # cov shape is now (batch, 5,5)\n",
    "  y_diff = y_pred[:,id] - y_true[:,id]\n",
    "  # y_diff = K.reshape(y_diff, (batch_size,1))\n",
    "  cov = K.reshape(cov[:,id,id], (batch_size,1))\n",
    "  # print(\"diff:\\n\",y_diff)\n",
    "  print(\"cov:\\n\",cov)\n",
    "  # return (y_diff*y_diff)/(cov[:,id,id])\n",
    "  return tf.math.square(y_diff)/(cov)\n",
    "\n",
    "# ccov = x_train[2][0:6]\n",
    "# ccov = np.reshape(ccov, (6,5,5))\n",
    "\n",
    "# print(ccov)\n",
    "\n",
    "# metric = K.eval(customMetric(y_train[0:6],y_train[1:7],x_train[2][0:6],0))\n",
    "# print(\"metric: \\n\",metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customMetric(y_true, y_pred, cov, id=0):\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "  y_pred = K.reshape(y_pred, (batch_size, 1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 1)) # y_state shape is now (batch, 5,1)\n",
    "  cov = K.reshape(cov, (batch_size, 5,5)) # cov  shape is now (batch, 5,5)\n",
    "  # cov = tf.transpose(cov, perm=[0,2,1])     # cov shape is now (batch, 5,5)\n",
    "  y_diff = y_pred - y_true\n",
    "  # y_diff = K.reshape(y_diff, (batch_size,1))\n",
    "  cov = K.reshape(cov[:,id,id], (batch_size,1))\n",
    "  # print(\"diff:\\n\",y_diff)\n",
    "  print(\"cov:\\n\",cov)\n",
    "  print(\"diff:\\n\",y_diff)\n",
    "  # return (y_diff*y_diff)/(cov[:,id,id])\n",
    "  return tf.math.square(y_diff)/(cov)\n",
    "\n",
    "# ccov = x_train[2][0:6]\n",
    "# ccov = np.reshape(ccov, (6,5,5))\n",
    "\n",
    "# print(ccov)\n",
    "\n",
    "# metric = K.eval(customMetric(y_train[0:6,0],y_train[1:7,0],x_train[2][0:6],3))\n",
    "# print(\"metric: \\n\",metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qw41A73h-zGB"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZ7d8PMx652m",
    "outputId": "aab903f4-7785-4519-ef41-4067f641d5e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov:\n",
      " Tensor(\"Reshape_3:0\", shape=(None, 1), dtype=float32)\n",
      "diff:\n",
      " Tensor(\"Sub:0\", shape=(None, 1), dtype=float32)\n",
      "Model: \"RNNModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 18)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_lstm1 (LSTM)              (None, None, 128)    75264       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm2 (LSTM)                    (None, None, 64)     49408       input_lstm1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm3 (LSTM)                    (None, 64)           33024       lstm2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 32)           2080        lstm3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output-Dense (Dense)            (None, 1)            33          Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           output-Dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1)]          0           output-Dense[0][0]               \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1)]          0           input_2[0][0]                    \n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 5, 5)]       0           input_4[0][0]                    \n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None,)]            0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 1)]          0           tf_op_layer_Sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 1)]          0           tf_op_layer_strided_slice_1[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv (TensorFlow [(None, 1)]          0           tf_op_layer_Square[0][0]         \n",
      "                                                                 tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_metric (AddMetric)          (None, 1)            0           tf_op_layer_RealDiv[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 159,809\n",
      "Trainable params: 159,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --==Not in use?==--\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.8)\n",
    "from keras.layers import Dense\n",
    "\n",
    "# nInput = 10\n",
    "nInput = 18\n",
    "\n",
    "# --==Set seed to get identical results==-- begin\n",
    "# from tensorflow.random import set_seed\n",
    "# np.random.seed(1)\n",
    "# set_seed(2)\n",
    "# --==Set seed to get identical results==-- end\n",
    "\n",
    "#--==Set Weights==--\n",
    "# loss_weights = [1/(sd**2)]\n",
    "# loss_weights = np.array(loss_weights)/sum(loss_weights)\n",
    "# model.compile(optimizer=optimizer, loss=\"mse\", loss_weights=loss_weights, metrics=[\"mae\"])\n",
    "\n",
    "inputs = keras.Input((None,nInput))\n",
    "# input_true = keras.Input((5,))\n",
    "input_true = keras.Input((1,))\n",
    "input_incov = keras.Input((25,))\n",
    "input_cov_f = keras.Input((25,))\n",
    "all_inputs = [inputs, input_incov, input_cov_f, input_true]\n",
    "# all_inputs = [inputs, input_incov, input_true]\n",
    "\n",
    "# --==Choose model==--\n",
    "# x = model(inputs)\n",
    "# x = model_timeless(inputs)\n",
    "# x = RNNTime(inputs)\n",
    "x = RNNTimeless(inputs)\n",
    "# x = RNNTimeStateful(inputs)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# outs = {\n",
    "#     \"q_pt\":Dense(1, name=\"q_pt\")(x),\n",
    "#     \"phi\":Dense(1, name=\"phi\")(x),\n",
    "#     \"tanl\":Dense(1, name=\"tanl\")(x),\n",
    "#     \"D\":Dense(1, name=\"D\")(x),\n",
    "#     \"z\":Dense(1, name=\"z\")(x)\n",
    "# }\n",
    "\n",
    "# y_dict = {\n",
    "#     \"q_pt\":y_train[:,0],\n",
    "#     \"phi\":y_train[:,1],\n",
    "#     \"tanl\":y_train[:,2],\n",
    "#     \"D\":y_train[:,3],\n",
    "#     \"z\":y_train[:,4]\n",
    "# }\n",
    "\n",
    "# model = keras.Model(inputs=all_inputs, outputs=outs, name=\"RNNModel\")\n",
    "\n",
    "model = keras.Model(inputs=all_inputs, outputs=x, name=\"RNNModel\")\n",
    "\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 0),name=\"q_pt\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 1),name=\"phi\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 2),name=\"tanl\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 3),name=\"D\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 4),name=\"z\")\n",
    "\n",
    "# model.add_loss(customLoss(input_true, x, input_incov))\n",
    "# model.compile(loss=None, optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "# model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.add_metric(customMetric(input_true, x, input_cov_f, 0),name=\"customMetric\")\n",
    "# try as loss\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "# model.compile(loss=\"\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkjx1-6Gr76F"
   },
   "source": [
    "### Custom Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t2pxxUfH7sjY"
   },
   "outputs": [],
   "source": [
    "def concat_hist(H1,H2):\n",
    "  H = {}\n",
    "  for i in H1.keys():\n",
    "    H[i] = list(np.append(np.array(H1[i]),np.array(H2[i])))\n",
    "  return H\n",
    "H = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjLh8Eh07HRW",
    "outputId": "e8312305-0acd-4240-c575-5b48161d1655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.6911 - mae: 0.9053 - customMetric: 317.6182 - val_loss: 2.3617 - val_mae: 1.0586 - val_customMetric: 105.1101\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7149 - mae: 0.9127 - customMetric: 323.7167 - val_loss: 2.4024 - val_mae: 1.0803 - val_customMetric: 112.0760\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7450 - mae: 0.9243 - customMetric: 294.0315 - val_loss: 2.4268 - val_mae: 1.0738 - val_customMetric: 112.4454\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7938 - mae: 0.9394 - customMetric: 328.4904 - val_loss: 2.3392 - val_mae: 1.0635 - val_customMetric: 106.3953\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.6967 - mae: 0.9036 - customMetric: 329.1071 - val_loss: 2.3495 - val_mae: 1.0637 - val_customMetric: 107.9406\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.7095 - mae: 0.9118 - customMetric: 312.9142 - val_loss: 2.3604 - val_mae: 1.0530 - val_customMetric: 114.0953\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7017 - mae: 0.9084 - customMetric: 316.6999 - val_loss: 2.3481 - val_mae: 1.0579 - val_customMetric: 109.6902\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7767 - mae: 0.9307 - customMetric: 326.0998 - val_loss: 2.3698 - val_mae: 1.0667 - val_customMetric: 108.6781\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7467 - mae: 0.9202 - customMetric: 329.6136 - val_loss: 2.3381 - val_mae: 1.0651 - val_customMetric: 107.3113\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.7067 - mae: 0.9080 - customMetric: 316.4917 - val_loss: 2.3609 - val_mae: 1.0612 - val_customMetric: 109.5853\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7148 - mae: 0.9105 - customMetric: 342.3542 - val_loss: 2.3444 - val_mae: 1.0602 - val_customMetric: 104.0219\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7104 - mae: 0.9083 - customMetric: 314.5886 - val_loss: 2.4955 - val_mae: 1.0778 - val_customMetric: 116.3797\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7876 - mae: 0.9296 - customMetric: 335.8843 - val_loss: 2.3420 - val_mae: 1.0569 - val_customMetric: 106.6850\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7157 - mae: 0.9144 - customMetric: 321.3603 - val_loss: 2.3637 - val_mae: 1.0658 - val_customMetric: 108.3862\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7226 - mae: 0.9190 - customMetric: 320.2888 - val_loss: 2.3606 - val_mae: 1.0597 - val_customMetric: 115.0472\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6900 - mae: 0.9054 - customMetric: 335.9359 - val_loss: 2.3344 - val_mae: 1.0530 - val_customMetric: 103.5795\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6826 - mae: 0.9006 - customMetric: 321.0499 - val_loss: 2.3298 - val_mae: 1.0504 - val_customMetric: 109.7421\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7007 - mae: 0.9059 - customMetric: 322.4125 - val_loss: 2.4051 - val_mae: 1.0696 - val_customMetric: 111.7217\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6815 - mae: 0.9005 - customMetric: 314.8579 - val_loss: 2.3289 - val_mae: 1.0544 - val_customMetric: 108.8044\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7016 - mae: 0.9053 - customMetric: 305.5008 - val_loss: 2.4104 - val_mae: 1.0623 - val_customMetric: 110.7845\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6694 - mae: 0.8976 - customMetric: 310.9150 - val_loss: 2.4115 - val_mae: 1.0785 - val_customMetric: 109.9765\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7196 - mae: 0.9148 - customMetric: 330.8166 - val_loss: 2.4101 - val_mae: 1.0723 - val_customMetric: 119.5471\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7233 - mae: 0.9153 - customMetric: 306.3087 - val_loss: 2.3843 - val_mae: 1.0665 - val_customMetric: 112.8961\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7549 - mae: 0.9225 - customMetric: 318.6881 - val_loss: 2.4168 - val_mae: 1.0766 - val_customMetric: 120.2471\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6985 - mae: 0.9061 - customMetric: 316.4594 - val_loss: 2.3482 - val_mae: 1.0593 - val_customMetric: 109.0132\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6809 - mae: 0.9027 - customMetric: 321.5334 - val_loss: 2.3388 - val_mae: 1.0489 - val_customMetric: 110.9058\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.7710 - mae: 0.9233 - customMetric: 328.6311 - val_loss: 2.5092 - val_mae: 1.1243 - val_customMetric: 128.3033\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.8387 - mae: 0.9559 - customMetric: 306.5033 - val_loss: 2.3393 - val_mae: 1.0589 - val_customMetric: 111.5956\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7146 - mae: 0.9126 - customMetric: 316.5407 - val_loss: 2.3807 - val_mae: 1.0659 - val_customMetric: 111.7357\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6846 - mae: 0.8999 - customMetric: 329.4717 - val_loss: 2.3733 - val_mae: 1.0630 - val_customMetric: 109.6463\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6624 - mae: 0.8944 - customMetric: 312.4605 - val_loss: 2.4040 - val_mae: 1.0707 - val_customMetric: 115.4292\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6863 - mae: 0.9004 - customMetric: 319.5263 - val_loss: 2.4301 - val_mae: 1.0749 - val_customMetric: 113.8284\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7279 - mae: 0.9078 - customMetric: 323.3990 - val_loss: 2.4216 - val_mae: 1.0778 - val_customMetric: 108.2852\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6961 - mae: 0.9043 - customMetric: 324.0858 - val_loss: 2.4132 - val_mae: 1.0763 - val_customMetric: 112.1007\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7169 - mae: 0.9096 - customMetric: 318.4448 - val_loss: 2.3775 - val_mae: 1.0777 - val_customMetric: 111.2318\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6688 - mae: 0.8971 - customMetric: 330.7387 - val_loss: 2.3923 - val_mae: 1.0648 - val_customMetric: 115.1307\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6739 - mae: 0.8973 - customMetric: 313.9681 - val_loss: 2.3806 - val_mae: 1.0710 - val_customMetric: 115.8260\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6914 - mae: 0.9031 - customMetric: 319.2734 - val_loss: 2.3969 - val_mae: 1.0684 - val_customMetric: 118.7345\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6741 - mae: 0.9000 - customMetric: 315.6159 - val_loss: 2.4076 - val_mae: 1.0844 - val_customMetric: 115.5997\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7710 - mae: 0.9310 - customMetric: 326.5129 - val_loss: 2.4387 - val_mae: 1.0920 - val_customMetric: 130.6420\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7061 - mae: 0.9074 - customMetric: 317.3453 - val_loss: 2.3927 - val_mae: 1.0584 - val_customMetric: 113.2249\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6836 - mae: 0.9014 - customMetric: 334.3328 - val_loss: 2.3587 - val_mae: 1.0562 - val_customMetric: 109.2979\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6613 - mae: 0.8919 - customMetric: 325.0353 - val_loss: 2.4591 - val_mae: 1.0698 - val_customMetric: 120.9055\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7451 - mae: 0.9139 - customMetric: 336.0371 - val_loss: 2.3749 - val_mae: 1.0605 - val_customMetric: 113.5651\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6735 - mae: 0.8975 - customMetric: 315.3815 - val_loss: 2.3655 - val_mae: 1.0623 - val_customMetric: 117.5804\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6726 - mae: 0.8963 - customMetric: 333.2672 - val_loss: 2.3730 - val_mae: 1.0596 - val_customMetric: 116.4429\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7529 - mae: 0.9232 - customMetric: 333.7239 - val_loss: 2.4302 - val_mae: 1.0767 - val_customMetric: 115.0960\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6934 - mae: 0.9044 - customMetric: 334.8069 - val_loss: 2.4304 - val_mae: 1.0676 - val_customMetric: 128.7195\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6492 - mae: 0.8892 - customMetric: 327.2273 - val_loss: 2.3891 - val_mae: 1.0686 - val_customMetric: 115.4153\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6548 - mae: 0.8909 - customMetric: 317.9448 - val_loss: 2.3989 - val_mae: 1.0595 - val_customMetric: 116.7288\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.6530 - mae: 0.8937 - customMetric: 328.8896 - val_loss: 2.4192 - val_mae: 1.0627 - val_customMetric: 112.9237\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6700 - mae: 0.8971 - customMetric: 325.0805 - val_loss: 2.4126 - val_mae: 1.0679 - val_customMetric: 117.5415\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.6321 - mae: 0.8833 - customMetric: 305.7184 - val_loss: 2.4028 - val_mae: 1.0621 - val_customMetric: 117.5439\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6417 - mae: 0.8863 - customMetric: 326.6384 - val_loss: 2.4216 - val_mae: 1.0744 - val_customMetric: 125.6865\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7178 - mae: 0.9100 - customMetric: 325.6323 - val_loss: 2.4312 - val_mae: 1.0738 - val_customMetric: 120.2015\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.6785 - mae: 0.8981 - customMetric: 322.3841 - val_loss: 2.4618 - val_mae: 1.0787 - val_customMetric: 131.0506\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6854 - mae: 0.9061 - customMetric: 313.5913 - val_loss: 2.3808 - val_mae: 1.0571 - val_customMetric: 114.8165\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6474 - mae: 0.8866 - customMetric: 319.5482 - val_loss: 2.4659 - val_mae: 1.0931 - val_customMetric: 127.4881\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6737 - mae: 0.8984 - customMetric: 321.5433 - val_loss: 2.3818 - val_mae: 1.0593 - val_customMetric: 110.2199\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6706 - mae: 0.8949 - customMetric: 328.4775 - val_loss: 2.3711 - val_mae: 1.0605 - val_customMetric: 116.5611\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6570 - mae: 0.8937 - customMetric: 314.3865 - val_loss: 2.4186 - val_mae: 1.0684 - val_customMetric: 116.0003\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6673 - mae: 0.8978 - customMetric: 321.6065 - val_loss: 2.3851 - val_mae: 1.0611 - val_customMetric: 112.8802\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.7322 - mae: 0.9132 - customMetric: 332.3695 - val_loss: 2.3795 - val_mae: 1.0706 - val_customMetric: 109.3906\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6879 - mae: 0.9038 - customMetric: 331.8902 - val_loss: 2.3717 - val_mae: 1.0576 - val_customMetric: 116.5067\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6725 - mae: 0.9024 - customMetric: 365.6099 - val_loss: 2.4547 - val_mae: 1.0701 - val_customMetric: 113.8929\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6420 - mae: 0.8905 - customMetric: 322.8932 - val_loss: 2.3854 - val_mae: 1.0549 - val_customMetric: 118.5808\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6470 - mae: 0.8850 - customMetric: 325.2059 - val_loss: 2.3860 - val_mae: 1.0585 - val_customMetric: 117.2613\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6408 - mae: 0.8849 - customMetric: 326.8730 - val_loss: 2.4575 - val_mae: 1.0729 - val_customMetric: 122.5278\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6759 - mae: 0.8979 - customMetric: 313.2758 - val_loss: 2.3578 - val_mae: 1.0551 - val_customMetric: 112.6451\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6200 - mae: 0.8828 - customMetric: 312.1003 - val_loss: 2.4056 - val_mae: 1.0608 - val_customMetric: 114.5987\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6102 - mae: 0.8773 - customMetric: 316.6767 - val_loss: 2.3501 - val_mae: 1.0575 - val_customMetric: 117.1940\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6237 - mae: 0.8828 - customMetric: 313.4480 - val_loss: 2.4208 - val_mae: 1.0618 - val_customMetric: 121.0596\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6939 - mae: 0.9022 - customMetric: 330.6584 - val_loss: 2.4021 - val_mae: 1.0709 - val_customMetric: 118.7465\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6342 - mae: 0.8846 - customMetric: 309.8409 - val_loss: 2.4117 - val_mae: 1.0617 - val_customMetric: 115.0681\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6075 - mae: 0.8770 - customMetric: 305.1967 - val_loss: 2.4160 - val_mae: 1.0726 - val_customMetric: 120.3169\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6223 - mae: 0.8807 - customMetric: 328.7214 - val_loss: 2.4971 - val_mae: 1.0806 - val_customMetric: 117.2794\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6298 - mae: 0.8818 - customMetric: 320.0766 - val_loss: 2.4483 - val_mae: 1.0724 - val_customMetric: 118.6293\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6309 - mae: 0.8827 - customMetric: 322.4814 - val_loss: 2.4385 - val_mae: 1.0644 - val_customMetric: 121.8708\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6390 - mae: 0.8878 - customMetric: 324.7227 - val_loss: 2.3772 - val_mae: 1.0639 - val_customMetric: 119.0859\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6274 - mae: 0.8825 - customMetric: 323.0512 - val_loss: 2.4271 - val_mae: 1.0601 - val_customMetric: 116.5296\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6680 - mae: 0.8933 - customMetric: 318.1422 - val_loss: 2.4828 - val_mae: 1.0742 - val_customMetric: 122.2666\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6177 - mae: 0.8812 - customMetric: 311.7265 - val_loss: 2.4551 - val_mae: 1.0675 - val_customMetric: 123.5112\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6255 - mae: 0.8809 - customMetric: 324.2577 - val_loss: 2.4069 - val_mae: 1.0621 - val_customMetric: 120.5620\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6407 - mae: 0.8915 - customMetric: 326.0978 - val_loss: 2.4303 - val_mae: 1.0647 - val_customMetric: 115.5987\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6054 - mae: 0.8746 - customMetric: 316.3441 - val_loss: 2.3704 - val_mae: 1.0527 - val_customMetric: 113.4064\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6618 - mae: 0.8896 - customMetric: 316.7452 - val_loss: 2.4049 - val_mae: 1.0631 - val_customMetric: 120.1261\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6114 - mae: 0.8757 - customMetric: 325.3056 - val_loss: 2.4253 - val_mae: 1.0620 - val_customMetric: 117.9228\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6104 - mae: 0.8734 - customMetric: 335.3849 - val_loss: 2.3917 - val_mae: 1.0595 - val_customMetric: 116.1872\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6607 - mae: 0.8908 - customMetric: 332.9124 - val_loss: 2.4341 - val_mae: 1.0590 - val_customMetric: 121.0543\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6153 - mae: 0.8764 - customMetric: 320.4708 - val_loss: 2.4660 - val_mae: 1.0714 - val_customMetric: 123.2162\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6337 - mae: 0.8849 - customMetric: 328.2393 - val_loss: 2.4063 - val_mae: 1.0629 - val_customMetric: 118.8654\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.6232 - mae: 0.8830 - customMetric: 323.9201 - val_loss: 2.4271 - val_mae: 1.0587 - val_customMetric: 117.6447\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5932 - mae: 0.8712 - customMetric: 305.7023 - val_loss: 2.4425 - val_mae: 1.0775 - val_customMetric: 122.2445\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5946 - mae: 0.8719 - customMetric: 323.5839 - val_loss: 2.4525 - val_mae: 1.0703 - val_customMetric: 121.5216\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6241 - mae: 0.8779 - customMetric: 325.8740 - val_loss: 2.4495 - val_mae: 1.0690 - val_customMetric: 118.0675\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6144 - mae: 0.8757 - customMetric: 326.4057 - val_loss: 2.4788 - val_mae: 1.0672 - val_customMetric: 119.6947\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6472 - mae: 0.8870 - customMetric: 326.4554 - val_loss: 2.4227 - val_mae: 1.0734 - val_customMetric: 118.7796\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.6596 - mae: 0.8934 - customMetric: 318.9578 - val_loss: 2.4287 - val_mae: 1.0653 - val_customMetric: 117.4928\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6180 - mae: 0.8760 - customMetric: 320.8734 - val_loss: 2.4682 - val_mae: 1.0750 - val_customMetric: 121.5719\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6865 - mae: 0.8987 - customMetric: 326.8458 - val_loss: 2.4402 - val_mae: 1.0690 - val_customMetric: 114.8051\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6430 - mae: 0.8882 - customMetric: 331.7885 - val_loss: 2.3908 - val_mae: 1.0551 - val_customMetric: 120.1333\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5819 - mae: 0.8719 - customMetric: 330.1096 - val_loss: 2.3937 - val_mae: 1.0569 - val_customMetric: 116.7587\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6243 - mae: 0.8803 - customMetric: 311.1313 - val_loss: 2.3988 - val_mae: 1.0582 - val_customMetric: 118.1070\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5918 - mae: 0.8727 - customMetric: 351.0811 - val_loss: 2.4485 - val_mae: 1.0772 - val_customMetric: 118.2764\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5974 - mae: 0.8694 - customMetric: 320.3773 - val_loss: 2.4431 - val_mae: 1.0707 - val_customMetric: 124.5807\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5842 - mae: 0.8696 - customMetric: 328.2034 - val_loss: 2.4796 - val_mae: 1.0779 - val_customMetric: 123.4929\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5676 - mae: 0.8626 - customMetric: 314.3219 - val_loss: 2.4119 - val_mae: 1.0541 - val_customMetric: 117.6025\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5760 - mae: 0.8627 - customMetric: 324.0874 - val_loss: 2.4346 - val_mae: 1.0691 - val_customMetric: 118.4616\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5890 - mae: 0.8723 - customMetric: 326.4735 - val_loss: 2.4021 - val_mae: 1.0528 - val_customMetric: 120.8095\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6506 - mae: 0.8894 - customMetric: 335.9846 - val_loss: 2.4504 - val_mae: 1.0689 - val_customMetric: 121.6534\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5904 - mae: 0.8689 - customMetric: 325.9312 - val_loss: 2.4267 - val_mae: 1.0647 - val_customMetric: 124.9574\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5732 - mae: 0.8645 - customMetric: 353.7143 - val_loss: 2.4968 - val_mae: 1.0745 - val_customMetric: 123.0733\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6033 - mae: 0.8778 - customMetric: 322.0941 - val_loss: 2.3892 - val_mae: 1.0519 - val_customMetric: 116.9735\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5556 - mae: 0.8595 - customMetric: 324.9054 - val_loss: 2.4171 - val_mae: 1.0614 - val_customMetric: 119.4532\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5756 - mae: 0.8633 - customMetric: 320.1336 - val_loss: 2.5089 - val_mae: 1.0773 - val_customMetric: 123.4600\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6007 - mae: 0.8700 - customMetric: 341.2092 - val_loss: 2.4154 - val_mae: 1.0692 - val_customMetric: 123.5229\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5913 - mae: 0.8742 - customMetric: 330.7386 - val_loss: 2.5709 - val_mae: 1.0820 - val_customMetric: 121.6862\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5971 - mae: 0.8689 - customMetric: 324.3954 - val_loss: 2.4518 - val_mae: 1.0611 - val_customMetric: 114.9372\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6235 - mae: 0.8811 - customMetric: 346.4448 - val_loss: 2.4478 - val_mae: 1.0628 - val_customMetric: 121.0608\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6319 - mae: 0.8803 - customMetric: 329.5443 - val_loss: 2.4550 - val_mae: 1.0646 - val_customMetric: 119.8474\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5959 - mae: 0.8723 - customMetric: 322.2768 - val_loss: 2.4575 - val_mae: 1.0754 - val_customMetric: 117.8589\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6456 - mae: 0.8923 - customMetric: 294.9297 - val_loss: 2.4082 - val_mae: 1.0693 - val_customMetric: 123.4192\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5863 - mae: 0.8674 - customMetric: 320.5206 - val_loss: 2.4960 - val_mae: 1.0711 - val_customMetric: 118.6462\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5689 - mae: 0.8646 - customMetric: 320.8364 - val_loss: 2.4465 - val_mae: 1.0699 - val_customMetric: 123.1697\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5675 - mae: 0.8606 - customMetric: 311.1555 - val_loss: 2.5150 - val_mae: 1.0675 - val_customMetric: 122.5952\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5967 - mae: 0.8712 - customMetric: 324.6389 - val_loss: 2.4119 - val_mae: 1.0506 - val_customMetric: 117.6187\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6354 - mae: 0.8861 - customMetric: 343.7871 - val_loss: 2.5116 - val_mae: 1.0859 - val_customMetric: 121.5070\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6432 - mae: 0.8849 - customMetric: 317.6497 - val_loss: 2.4607 - val_mae: 1.0660 - val_customMetric: 117.7373\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5620 - mae: 0.8631 - customMetric: 318.9224 - val_loss: 2.4258 - val_mae: 1.0553 - val_customMetric: 121.6528\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6059 - mae: 0.8798 - customMetric: 317.0780 - val_loss: 2.5183 - val_mae: 1.0793 - val_customMetric: 132.1086\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6624 - mae: 0.8894 - customMetric: 317.5768 - val_loss: 2.4117 - val_mae: 1.0647 - val_customMetric: 124.4514\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6258 - mae: 0.8795 - customMetric: 337.8442 - val_loss: 2.5085 - val_mae: 1.0839 - val_customMetric: 121.3074\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6433 - mae: 0.8897 - customMetric: 325.8813 - val_loss: 2.4465 - val_mae: 1.0769 - val_customMetric: 122.8730\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6164 - mae: 0.8801 - customMetric: 327.3265 - val_loss: 2.4127 - val_mae: 1.0571 - val_customMetric: 120.8897\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5481 - mae: 0.8550 - customMetric: 326.2079 - val_loss: 2.3853 - val_mae: 1.0619 - val_customMetric: 123.7499\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5973 - mae: 0.8728 - customMetric: 356.0157 - val_loss: 2.4831 - val_mae: 1.0728 - val_customMetric: 123.4833\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5600 - mae: 0.8571 - customMetric: 327.0928 - val_loss: 2.4873 - val_mae: 1.0799 - val_customMetric: 122.0447\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5636 - mae: 0.8622 - customMetric: 323.3713 - val_loss: 2.4305 - val_mae: 1.0709 - val_customMetric: 128.0367\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5457 - mae: 0.8546 - customMetric: 330.1443 - val_loss: 2.4686 - val_mae: 1.0698 - val_customMetric: 127.5403\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5319 - mae: 0.8537 - customMetric: 327.5509 - val_loss: 2.4677 - val_mae: 1.0739 - val_customMetric: 128.4041\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5622 - mae: 0.8584 - customMetric: 314.7958 - val_loss: 2.4521 - val_mae: 1.0660 - val_customMetric: 123.3339\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5735 - mae: 0.8658 - customMetric: 331.9373 - val_loss: 2.5013 - val_mae: 1.0792 - val_customMetric: 121.7295\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5776 - mae: 0.8703 - customMetric: 315.1547 - val_loss: 2.4519 - val_mae: 1.0632 - val_customMetric: 122.0176\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5832 - mae: 0.8671 - customMetric: 324.2474 - val_loss: 2.4248 - val_mae: 1.0602 - val_customMetric: 119.7483\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5662 - mae: 0.8589 - customMetric: 329.3479 - val_loss: 2.4268 - val_mae: 1.0629 - val_customMetric: 125.8701\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5676 - mae: 0.8623 - customMetric: 333.2733 - val_loss: 2.4718 - val_mae: 1.0727 - val_customMetric: 130.9323\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6329 - mae: 0.8793 - customMetric: 323.3808 - val_loss: 2.4825 - val_mae: 1.0752 - val_customMetric: 122.6250\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5368 - mae: 0.8552 - customMetric: 334.3923 - val_loss: 2.4907 - val_mae: 1.0758 - val_customMetric: 123.5700\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5285 - mae: 0.8532 - customMetric: 331.5167 - val_loss: 2.4728 - val_mae: 1.0640 - val_customMetric: 123.9958\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5811 - mae: 0.8660 - customMetric: 335.8937 - val_loss: 2.5234 - val_mae: 1.0712 - val_customMetric: 119.6165\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5600 - mae: 0.8619 - customMetric: 329.6797 - val_loss: 2.4360 - val_mae: 1.0661 - val_customMetric: 123.5862\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6188 - mae: 0.8807 - customMetric: 350.0894 - val_loss: 2.4344 - val_mae: 1.0611 - val_customMetric: 120.9522\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5765 - mae: 0.8666 - customMetric: 315.0906 - val_loss: 2.4625 - val_mae: 1.0647 - val_customMetric: 123.9312\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5255 - mae: 0.8480 - customMetric: 307.7019 - val_loss: 2.5549 - val_mae: 1.0926 - val_customMetric: 125.2786\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5439 - mae: 0.8586 - customMetric: 320.7266 - val_loss: 2.5054 - val_mae: 1.0722 - val_customMetric: 120.3481\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5674 - mae: 0.8674 - customMetric: 308.7478 - val_loss: 2.4888 - val_mae: 1.0752 - val_customMetric: 135.3438\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5471 - mae: 0.8562 - customMetric: 332.9570 - val_loss: 2.4796 - val_mae: 1.0650 - val_customMetric: 122.1665\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5403 - mae: 0.8554 - customMetric: 329.0061 - val_loss: 2.4206 - val_mae: 1.0472 - val_customMetric: 120.8524\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5156 - mae: 0.8431 - customMetric: 319.0267 - val_loss: 2.3822 - val_mae: 1.0509 - val_customMetric: 123.9522\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5371 - mae: 0.8520 - customMetric: 322.8806 - val_loss: 2.4945 - val_mae: 1.0697 - val_customMetric: 124.0549\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6629 - mae: 0.8903 - customMetric: 348.3459 - val_loss: 2.5158 - val_mae: 1.0802 - val_customMetric: 125.6314\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.6996 - mae: 0.8977 - customMetric: 320.6063 - val_loss: 2.4806 - val_mae: 1.0757 - val_customMetric: 128.4945\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5427 - mae: 0.8611 - customMetric: 334.3357 - val_loss: 2.4643 - val_mae: 1.0731 - val_customMetric: 121.3792\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5652 - mae: 0.8595 - customMetric: 324.4902 - val_loss: 2.5164 - val_mae: 1.0724 - val_customMetric: 124.6470\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5322 - mae: 0.8546 - customMetric: 333.2947 - val_loss: 2.4499 - val_mae: 1.0619 - val_customMetric: 121.1451\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5201 - mae: 0.8474 - customMetric: 319.5040 - val_loss: 2.4578 - val_mae: 1.0610 - val_customMetric: 125.5659\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5184 - mae: 0.8481 - customMetric: 311.7406 - val_loss: 2.4195 - val_mae: 1.0567 - val_customMetric: 124.9715\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5802 - mae: 0.8628 - customMetric: 322.7766 - val_loss: 2.4694 - val_mae: 1.0702 - val_customMetric: 124.5542\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5539 - mae: 0.8596 - customMetric: 304.2480 - val_loss: 2.4540 - val_mae: 1.0711 - val_customMetric: 124.8951\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5462 - mae: 0.8582 - customMetric: 335.4307 - val_loss: 2.5567 - val_mae: 1.0919 - val_customMetric: 120.8252\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5761 - mae: 0.8630 - customMetric: 321.8366 - val_loss: 2.4625 - val_mae: 1.0562 - val_customMetric: 126.7501\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5201 - mae: 0.8457 - customMetric: 338.3944 - val_loss: 2.4915 - val_mae: 1.0698 - val_customMetric: 123.9554\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5288 - mae: 0.8548 - customMetric: 321.9973 - val_loss: 2.5455 - val_mae: 1.0785 - val_customMetric: 126.1133\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5453 - mae: 0.8554 - customMetric: 316.0369 - val_loss: 2.5223 - val_mae: 1.0818 - val_customMetric: 141.2274\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5187 - mae: 0.8485 - customMetric: 320.7317 - val_loss: 2.4885 - val_mae: 1.0638 - val_customMetric: 127.2907\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5110 - mae: 0.8463 - customMetric: 327.0787 - val_loss: 2.5010 - val_mae: 1.0668 - val_customMetric: 121.0643\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5189 - mae: 0.8478 - customMetric: 311.4609 - val_loss: 2.5103 - val_mae: 1.0720 - val_customMetric: 123.5530\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6587 - mae: 0.8841 - customMetric: 353.3941 - val_loss: 2.5577 - val_mae: 1.0886 - val_customMetric: 124.3211\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5484 - mae: 0.8580 - customMetric: 314.5563 - val_loss: 2.4915 - val_mae: 1.0759 - val_customMetric: 125.3939\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5276 - mae: 0.8483 - customMetric: 315.3942 - val_loss: 2.4142 - val_mae: 1.0595 - val_customMetric: 121.0330\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4796 - mae: 0.8361 - customMetric: 315.0107 - val_loss: 2.4290 - val_mae: 1.0606 - val_customMetric: 124.2222\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5165 - mae: 0.8477 - customMetric: 321.8412 - val_loss: 2.5471 - val_mae: 1.0771 - val_customMetric: 125.0167\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5207 - mae: 0.8490 - customMetric: 321.0939 - val_loss: 2.4889 - val_mae: 1.0630 - val_customMetric: 124.7626\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.5302 - mae: 0.8497 - customMetric: 331.2726 - val_loss: 2.5330 - val_mae: 1.0821 - val_customMetric: 123.4052\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5249 - mae: 0.8480 - customMetric: 336.5428 - val_loss: 2.4043 - val_mae: 1.0519 - val_customMetric: 121.7829\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5204 - mae: 0.8491 - customMetric: 327.5922 - val_loss: 2.4253 - val_mae: 1.0484 - val_customMetric: 120.2546\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4776 - mae: 0.8325 - customMetric: 326.6081 - val_loss: 2.4372 - val_mae: 1.0519 - val_customMetric: 121.3991\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5131 - mae: 0.8410 - customMetric: 320.4386 - val_loss: 2.4834 - val_mae: 1.0713 - val_customMetric: 124.1330\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5495 - mae: 0.8537 - customMetric: 314.0704 - val_loss: 2.5527 - val_mae: 1.0734 - val_customMetric: 125.6520\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5448 - mae: 0.8553 - customMetric: 321.2975 - val_loss: 2.4186 - val_mae: 1.0497 - val_customMetric: 118.9009\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5453 - mae: 0.8528 - customMetric: 319.0620 - val_loss: 2.4093 - val_mae: 1.0533 - val_customMetric: 120.5071\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5049 - mae: 0.8451 - customMetric: 324.6524 - val_loss: 2.4336 - val_mae: 1.0550 - val_customMetric: 121.3906\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4888 - mae: 0.8340 - customMetric: 308.3372 - val_loss: 2.4482 - val_mae: 1.0630 - val_customMetric: 123.3917\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4845 - mae: 0.8357 - customMetric: 324.0446 - val_loss: 2.5103 - val_mae: 1.0755 - val_customMetric: 123.1319\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4895 - mae: 0.8373 - customMetric: 312.1983 - val_loss: 2.3835 - val_mae: 1.0462 - val_customMetric: 123.2465\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5506 - mae: 0.8573 - customMetric: 309.1661 - val_loss: 2.5285 - val_mae: 1.0715 - val_customMetric: 125.7150\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4958 - mae: 0.8369 - customMetric: 320.5057 - val_loss: 2.4997 - val_mae: 1.0678 - val_customMetric: 125.7452\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4647 - mae: 0.8314 - customMetric: 320.9336 - val_loss: 2.5539 - val_mae: 1.0826 - val_customMetric: 124.8950\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4763 - mae: 0.8368 - customMetric: 319.1652 - val_loss: 2.5111 - val_mae: 1.0725 - val_customMetric: 127.8159\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4766 - mae: 0.8370 - customMetric: 319.9210 - val_loss: 2.4815 - val_mae: 1.0685 - val_customMetric: 126.4747\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5126 - mae: 0.8404 - customMetric: 336.2035 - val_loss: 2.5462 - val_mae: 1.0787 - val_customMetric: 123.1099\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5225 - mae: 0.8475 - customMetric: 317.9642 - val_loss: 2.5188 - val_mae: 1.0704 - val_customMetric: 129.3841\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4764 - mae: 0.8314 - customMetric: 315.7915 - val_loss: 2.5076 - val_mae: 1.0730 - val_customMetric: 127.2826\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5030 - mae: 0.8438 - customMetric: 314.8130 - val_loss: 2.5002 - val_mae: 1.0712 - val_customMetric: 125.1951\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5627 - mae: 0.8576 - customMetric: 319.4727 - val_loss: 2.5009 - val_mae: 1.0665 - val_customMetric: 123.6826\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4762 - mae: 0.8358 - customMetric: 318.7925 - val_loss: 2.4928 - val_mae: 1.0670 - val_customMetric: 122.0338\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4648 - mae: 0.8294 - customMetric: 333.1911 - val_loss: 2.5222 - val_mae: 1.0736 - val_customMetric: 124.6440\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4860 - mae: 0.8347 - customMetric: 324.2525 - val_loss: 2.4712 - val_mae: 1.0660 - val_customMetric: 122.5270\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5258 - mae: 0.8466 - customMetric: 320.6172 - val_loss: 2.4421 - val_mae: 1.0531 - val_customMetric: 121.1015\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4724 - mae: 0.8356 - customMetric: 334.5896 - val_loss: 2.4786 - val_mae: 1.0620 - val_customMetric: 125.2589\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4868 - mae: 0.8350 - customMetric: 317.6524 - val_loss: 2.6025 - val_mae: 1.0903 - val_customMetric: 127.6273\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5147 - mae: 0.8446 - customMetric: 322.4891 - val_loss: 2.4162 - val_mae: 1.0605 - val_customMetric: 127.9955\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4763 - mae: 0.8375 - customMetric: 313.9447 - val_loss: 2.4756 - val_mae: 1.0602 - val_customMetric: 124.7397\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5434 - mae: 0.8515 - customMetric: 346.4413 - val_loss: 2.5280 - val_mae: 1.0823 - val_customMetric: 120.4896\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5409 - mae: 0.8576 - customMetric: 323.4010 - val_loss: 2.5523 - val_mae: 1.0814 - val_customMetric: 123.4713\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6931 - mae: 0.8941 - customMetric: 374.7745 - val_loss: 2.4361 - val_mae: 1.0627 - val_customMetric: 121.6224\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5087 - mae: 0.8467 - customMetric: 317.6028 - val_loss: 2.4956 - val_mae: 1.0693 - val_customMetric: 126.3685\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5277 - mae: 0.8524 - customMetric: 324.3800 - val_loss: 2.4843 - val_mae: 1.0619 - val_customMetric: 127.0290\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4601 - mae: 0.8286 - customMetric: 312.6167 - val_loss: 2.5364 - val_mae: 1.0691 - val_customMetric: 124.8909\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4651 - mae: 0.8284 - customMetric: 313.5571 - val_loss: 2.5258 - val_mae: 1.0695 - val_customMetric: 126.2202\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4970 - mae: 0.8391 - customMetric: 334.6247 - val_loss: 2.4969 - val_mae: 1.0748 - val_customMetric: 128.1648\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4700 - mae: 0.8338 - customMetric: 319.8994 - val_loss: 2.5549 - val_mae: 1.0719 - val_customMetric: 129.5571\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4539 - mae: 0.8262 - customMetric: 324.3627 - val_loss: 2.5312 - val_mae: 1.0735 - val_customMetric: 128.5919\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5015 - mae: 0.8406 - customMetric: 333.0388 - val_loss: 2.4984 - val_mae: 1.0580 - val_customMetric: 126.4495\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4956 - mae: 0.8400 - customMetric: 313.3147 - val_loss: 2.5849 - val_mae: 1.0806 - val_customMetric: 129.8968\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5417 - mae: 0.8532 - customMetric: 308.7697 - val_loss: 2.4905 - val_mae: 1.0689 - val_customMetric: 132.5913\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5340 - mae: 0.8523 - customMetric: 325.6747 - val_loss: 2.4690 - val_mae: 1.0610 - val_customMetric: 121.3764\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5353 - mae: 0.8542 - customMetric: 340.7946 - val_loss: 2.4429 - val_mae: 1.0555 - val_customMetric: 124.9611\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5741 - mae: 0.8639 - customMetric: 311.2161 - val_loss: 2.5241 - val_mae: 1.0706 - val_customMetric: 124.8846\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5606 - mae: 0.8656 - customMetric: 341.3589 - val_loss: 2.5975 - val_mae: 1.0858 - val_customMetric: 127.4331\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4765 - mae: 0.8366 - customMetric: 315.7485 - val_loss: 2.5178 - val_mae: 1.0679 - val_customMetric: 131.0736\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4547 - mae: 0.8275 - customMetric: 322.4809 - val_loss: 2.4251 - val_mae: 1.0508 - val_customMetric: 125.0740\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4477 - mae: 0.8283 - customMetric: 323.7813 - val_loss: 2.4946 - val_mae: 1.0674 - val_customMetric: 126.1010\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4611 - mae: 0.8280 - customMetric: 301.9543 - val_loss: 2.5405 - val_mae: 1.0719 - val_customMetric: 127.6184\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4414 - mae: 0.8264 - customMetric: 327.4207 - val_loss: 2.5103 - val_mae: 1.0688 - val_customMetric: 127.8432\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4511 - mae: 0.8256 - customMetric: 312.6367 - val_loss: 2.5334 - val_mae: 1.0808 - val_customMetric: 125.8177\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4838 - mae: 0.8392 - customMetric: 338.8477 - val_loss: 2.5751 - val_mae: 1.0834 - val_customMetric: 126.1887\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5143 - mae: 0.8464 - customMetric: 306.3755 - val_loss: 2.4797 - val_mae: 1.0717 - val_customMetric: 126.8864\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4500 - mae: 0.8292 - customMetric: 321.7752 - val_loss: 2.5622 - val_mae: 1.0756 - val_customMetric: 128.6951\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4429 - mae: 0.8222 - customMetric: 310.8346 - val_loss: 2.5176 - val_mae: 1.0725 - val_customMetric: 125.7834\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4370 - mae: 0.8222 - customMetric: 314.9257 - val_loss: 2.5408 - val_mae: 1.0732 - val_customMetric: 135.0276\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4394 - mae: 0.8245 - customMetric: 322.2247 - val_loss: 2.5530 - val_mae: 1.0675 - val_customMetric: 129.1112\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4603 - mae: 0.8281 - customMetric: 325.9026 - val_loss: 2.5275 - val_mae: 1.0666 - val_customMetric: 133.8566\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4815 - mae: 0.8363 - customMetric: 325.8992 - val_loss: 2.5232 - val_mae: 1.0730 - val_customMetric: 128.7036\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4194 - mae: 0.8158 - customMetric: 323.2347 - val_loss: 2.4926 - val_mae: 1.0597 - val_customMetric: 128.3356\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.4344 - mae: 0.8221 - customMetric: 318.2752 - val_loss: 2.4816 - val_mae: 1.0593 - val_customMetric: 125.5473\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4524 - mae: 0.8231 - customMetric: 321.2997 - val_loss: 2.6495 - val_mae: 1.0888 - val_customMetric: 130.9634\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4964 - mae: 0.8365 - customMetric: 317.9081 - val_loss: 2.5484 - val_mae: 1.0752 - val_customMetric: 124.5463\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4342 - mae: 0.8260 - customMetric: 318.4743 - val_loss: 2.4959 - val_mae: 1.0579 - val_customMetric: 127.0400\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4796 - mae: 0.8331 - customMetric: 323.4222 - val_loss: 2.5564 - val_mae: 1.0729 - val_customMetric: 131.5301\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4769 - mae: 0.8324 - customMetric: 309.4822 - val_loss: 2.7434 - val_mae: 1.1109 - val_customMetric: 128.1223\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5941 - mae: 0.8635 - customMetric: 304.5115 - val_loss: 2.5540 - val_mae: 1.0799 - val_customMetric: 126.6490\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4084 - mae: 0.8158 - customMetric: 325.0254 - val_loss: 2.5379 - val_mae: 1.0698 - val_customMetric: 131.1633\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4018 - mae: 0.8082 - customMetric: 328.0732 - val_loss: 2.5145 - val_mae: 1.0633 - val_customMetric: 127.8206\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4271 - mae: 0.8219 - customMetric: 325.2466 - val_loss: 2.5595 - val_mae: 1.0701 - val_customMetric: 127.7407\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4448 - mae: 0.8225 - customMetric: 305.9375 - val_loss: 2.5907 - val_mae: 1.0734 - val_customMetric: 132.8255\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5876 - mae: 0.8672 - customMetric: 328.4104 - val_loss: 2.5861 - val_mae: 1.1036 - val_customMetric: 126.6931\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4411 - mae: 0.8262 - customMetric: 328.1991 - val_loss: 2.5299 - val_mae: 1.0662 - val_customMetric: 124.0424\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4635 - mae: 0.8329 - customMetric: 327.6855 - val_loss: 2.5318 - val_mae: 1.0637 - val_customMetric: 125.3630\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4588 - mae: 0.8246 - customMetric: 320.2766 - val_loss: 2.4807 - val_mae: 1.0587 - val_customMetric: 120.2451\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4892 - mae: 0.8392 - customMetric: 343.7512 - val_loss: 2.5042 - val_mae: 1.0862 - val_customMetric: 122.2715\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6132 - mae: 0.8761 - customMetric: 370.3020 - val_loss: 2.5329 - val_mae: 1.0647 - val_customMetric: 119.2544\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4409 - mae: 0.8210 - customMetric: 311.5073 - val_loss: 2.5431 - val_mae: 1.0772 - val_customMetric: 127.9817\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4366 - mae: 0.8195 - customMetric: 320.5945 - val_loss: 2.6995 - val_mae: 1.0995 - val_customMetric: 133.3675\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5917 - mae: 0.8634 - customMetric: 307.8835 - val_loss: 2.5080 - val_mae: 1.0582 - val_customMetric: 127.8271\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4417 - mae: 0.8268 - customMetric: 336.1761 - val_loss: 2.5752 - val_mae: 1.0841 - val_customMetric: 143.8025\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4298 - mae: 0.8187 - customMetric: 321.2876 - val_loss: 2.5256 - val_mae: 1.0678 - val_customMetric: 130.6363\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6430 - mae: 0.8848 - customMetric: 362.5235 - val_loss: 2.5372 - val_mae: 1.0642 - val_customMetric: 125.0153\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4747 - mae: 0.8290 - customMetric: 308.2147 - val_loss: 2.5337 - val_mae: 1.0724 - val_customMetric: 128.8956\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.5095 - mae: 0.8415 - customMetric: 343.1362 - val_loss: 2.4882 - val_mae: 1.0667 - val_customMetric: 125.1864\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4179 - mae: 0.8145 - customMetric: 323.8632 - val_loss: 2.4839 - val_mae: 1.0568 - val_customMetric: 126.4499\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4844 - mae: 0.8350 - customMetric: 347.3723 - val_loss: 2.5074 - val_mae: 1.0587 - val_customMetric: 120.5494\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4628 - mae: 0.8327 - customMetric: 318.1916 - val_loss: 2.5500 - val_mae: 1.0710 - val_customMetric: 127.6194\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3928 - mae: 0.8091 - customMetric: 319.1402 - val_loss: 2.5095 - val_mae: 1.0626 - val_customMetric: 129.0320\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3836 - mae: 0.8051 - customMetric: 316.9843 - val_loss: 2.5305 - val_mae: 1.0645 - val_customMetric: 129.7105\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3877 - mae: 0.8075 - customMetric: 328.6670 - val_loss: 2.5322 - val_mae: 1.0697 - val_customMetric: 127.6785\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3992 - mae: 0.8075 - customMetric: 318.8499 - val_loss: 2.5294 - val_mae: 1.0674 - val_customMetric: 134.6349\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4668 - mae: 0.8279 - customMetric: 318.2171 - val_loss: 2.6156 - val_mae: 1.0864 - val_customMetric: 134.2899\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4545 - mae: 0.8288 - customMetric: 310.5666 - val_loss: 2.6138 - val_mae: 1.0852 - val_customMetric: 129.6155\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3969 - mae: 0.8096 - customMetric: 320.8035 - val_loss: 2.5090 - val_mae: 1.0601 - val_customMetric: 131.0554\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3740 - mae: 0.8031 - customMetric: 321.0265 - val_loss: 2.5345 - val_mae: 1.0680 - val_customMetric: 129.9326\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4129 - mae: 0.8103 - customMetric: 309.6738 - val_loss: 2.5615 - val_mae: 1.0719 - val_customMetric: 132.1467\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 1.4839 - mae: 0.8334 - customMetric: 337.8780 - val_loss: 2.5395 - val_mae: 1.0696 - val_customMetric: 127.3310\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4116 - mae: 0.8139 - customMetric: 305.6561 - val_loss: 2.4676 - val_mae: 1.0580 - val_customMetric: 125.3975\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4504 - mae: 0.8240 - customMetric: 320.2701 - val_loss: 2.6752 - val_mae: 1.1021 - val_customMetric: 129.5876\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 2.3468 - mae: 1.0772 - customMetric: 397.3671 - val_loss: 2.7645 - val_mae: 1.1927 - val_customMetric: 128.4535\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 2.2147 - mae: 1.0613 - customMetric: 331.4926 - val_loss: 2.8214 - val_mae: 1.1933 - val_customMetric: 147.5588\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 2.2336 - mae: 1.0723 - customMetric: 379.5276 - val_loss: 2.6360 - val_mae: 1.1642 - val_customMetric: 119.7936\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.9607 - mae: 0.9940 - customMetric: 344.4291 - val_loss: 2.5654 - val_mae: 1.1328 - val_customMetric: 120.9955\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7429 - mae: 0.9285 - customMetric: 335.2001 - val_loss: 2.4781 - val_mae: 1.0817 - val_customMetric: 119.9582\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6708 - mae: 0.8901 - customMetric: 304.4157 - val_loss: 2.4949 - val_mae: 1.0811 - val_customMetric: 134.6009\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.5177 - mae: 0.8520 - customMetric: 311.1703 - val_loss: 2.4948 - val_mae: 1.0730 - val_customMetric: 125.9242\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4154 - mae: 0.8180 - customMetric: 304.5207 - val_loss: 2.4368 - val_mae: 1.0566 - val_customMetric: 128.0394\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3845 - mae: 0.8087 - customMetric: 310.5189 - val_loss: 2.5332 - val_mae: 1.0677 - val_customMetric: 129.0188\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3922 - mae: 0.8070 - customMetric: 312.1512 - val_loss: 2.5523 - val_mae: 1.0707 - val_customMetric: 126.6499\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3988 - mae: 0.8074 - customMetric: 320.4986 - val_loss: 2.5269 - val_mae: 1.0723 - val_customMetric: 129.2285\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.4070 - mae: 0.8099 - customMetric: 313.2878 - val_loss: 2.4956 - val_mae: 1.0572 - val_customMetric: 123.9285\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3686 - mae: 0.8020 - customMetric: 314.6987 - val_loss: 2.5654 - val_mae: 1.0711 - val_customMetric: 126.9374\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.3775 - mae: 0.8027 - customMetric: 316.6143 - val_loss: 2.5016 - val_mae: 1.0581 - val_customMetric: 126.9045\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.3752 - mae: 0.8029 - customMetric: 312.5983 - val_loss: 2.5305 - val_mae: 1.0679 - val_customMetric: 125.6872\n"
     ]
    }
   ],
   "source": [
    "H_t = []\n",
    "index = 1\n",
    "\n",
    "# Using custom loss and gen\n",
    "es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=25, mode='min', verbose=1, restore_best_weights=True)\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=64, epochs=300, validation_data=(x_test, y_test), verbose=1, callbacks=[es])\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=64, epochs=300, shuffle=True, verbose=1, callbacks=[es])\n",
    "# H = model.fit(x=x_train, y=y_train[:,2], batch_size=256, epochs=300, verbose=1, shuffle=True, callbacks=[es])\n",
    "# H_t.append(model.fit(x=x_train, y=y_train[:,2], batch_size=256, epochs=300, verbose=1, shuffle=True, callbacks=[es]).history)\n",
    "# H_t.append(model.fit(x=x_train, y=y_train[:,index], batch_size=256, epochs=300, verbose=1, shuffle=True, callbacks=[es]).history)\n",
    "H_t.append(model.fit(x=x_train, y=y_train, batch_size=256, epochs=300, verbose=1, validation_data=(x_test, y_test), shuffle=True).history)\n",
    "# model.fit(x=[x_train[0],x_train[1],x_train[2],np.expand_dims(x_train[3][:,index],-1)], y=y_train[:,index], batch_size=256, epochs=300, verbose=1, shuffle=True)\n",
    "if H == None:\n",
    "  H = H_t[-1]\n",
    "else:\n",
    "  H = concat_hist(H,H_t[-1])\n",
    "final_loss = round(H[\"loss\"][-1],2)\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=64, epochs=100, validation_data=test_gen, validation_steps=50, validation_batch_size=32, verbose=1)\n",
    "\n",
    "# Example how it kind of looks like\n",
    "# H = model.fit(x=[x_train, invCov, y_train], y=y_train, batch_size=64, epochs=100, verbose=1)\n",
    "\n",
    "# Overfit\n",
    "# es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=100, mode='min', verbose=1, restore_best_weights=True)\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=1, epochs=100, verbose=1, callbacks=[es])\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=1, epochs=100, verbose=1, validation_data=(x_test,y_test), callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ5XBwDV7MGY"
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = 1\n",
    "date = \"03-08\"\n",
    "final_loss = 0\n",
    "def gen_name(m_type):\n",
    "    global model_index, index, date, final_loss\n",
    "    variable = [\"q_pt\",\"phi\",\"tanl\",\"D\",\"z\"][index]\n",
    "    m_str = \"models/\" + str(date) + \"-2021_\" + str(variable) + \"-\" + str(model_index) + \"_loss=\" + str(final_loss) + \".\" + str(m_type)\n",
    "    model_index+=1 # create a check for if file exists, for now just increment\n",
    "    return m_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWvST6o27MYI"
   },
   "outputs": [],
   "source": [
    "# model.save('model.h5', save_format=\"h5\")\n",
    "# TODO check if file exists, increment counter\n",
    "# model.save('drive/MyDrive/Models/RealRNN_1-3-2021_141Ep_Onlytanl-2.h5', save_format=\"h5\")\n",
    "model.save(gen_name(\"h5\"), save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6LGBSia7fg3"
   },
   "source": [
    "## Graph loss and mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "OUPAStLMtq7m",
    "outputId": "d4bada3c-6f91-4a9c-b6d7-d7abe8cc1689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'customMetric', 'val_loss', 'val_mae', 'val_customMetric'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(H.keys())\n",
    "# print(\"loss: \", H[\"loss\"])\n",
    "# print(\"mae: \", H[\"mae\"])\n",
    "# print(\"val_loss: \", H.history[\"val_loss\"])\n",
    "# print(\"val_mae: \", H.history[\"val_mae\"])\n",
    "\n",
    "lim = 0\n",
    "\n",
    "fig, ax = plt.subplots(3,1,figsize=(5,15))\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "ax[0].plot(H[\"loss\"][lim:])\n",
    "ax[0].plot(H[\"val_loss\"][lim:])\n",
    "ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "ax[0].legend([\"train\",\"val\"])\n",
    "ax[0].grid(True)\n",
    "\n",
    "\n",
    "ax[1].plot(H[\"mae\"][lim:])\n",
    "ax[1].plot(H[\"val_mae\"][lim:])\n",
    "ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "ax[1].legend([\"train\",\"val\"])\n",
    "ax[1].grid(True)\n",
    "\n",
    "ax[2].plot(H[\"customMetric\"][lim:])\n",
    "ax[2].plot(H[\"val_customMetric\"][lim:])\n",
    "ax[2].set_title(\"metric vs epoch\", fontsize=20)\n",
    "ax[2].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[2].set_ylabel(\"metric\", fontsize=15)\n",
    "ax[2].legend([\"train\",\"val\"])\n",
    "ax[2].grid(True)\n",
    "\n",
    "model_index -= 1\n",
    "plt.savefig(gen_name(\"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array = np.array(list(H.items()))\n",
    "save_array = np.array([an_array[0][1],an_array[1][1]])\n",
    "model_index -= 1\n",
    "np.save(gen_name(\"npy\"),save_array,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw4xzpuKYEld"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZHLFMS1YE40",
    "outputId": "09e30fe4-cc1b-444f-83b3-c74d1b923762"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "from time import sleep\n",
    "\n",
    "for i in range(10):\n",
    "  aax = x_train[0][i:i+1]\n",
    "  oax = x_train[1][i:i+1]\n",
    "  cax = x_train[2][i:i+1]\n",
    "  yax = x_train[3][i:i+1]\n",
    "  aay = y_train[i][index]\n",
    "  pred = model.predict([aax, oax, cax, yax])[0][0]\n",
    "  diff = pred - aay\n",
    "  # print(\"i: \",i)\n",
    "  # print(\"aax:  \",aax[0,0])\n",
    "  print(\"aay:  \",aay)\n",
    "  print(\"pred: \",pred)\n",
    "  # print(\"diff: \",diff)\n",
    "  print(\"\")\n",
    "\n",
    "  # plt.plot(aay[0])\n",
    "  # plt.plot(pred[0])\n",
    "  # plt.show()\n",
    "# [Q/PT, phi, tanl, D, z]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T56J0X6g7O2k"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgLQh0jf7Ova"
   },
   "outputs": [],
   "source": [
    "# model.save('drive/MyDrive/RealRNN_1-2-2021_2.h5', save_format=\"h5\")\n",
    "model = keras.models.load_model('drive/MyDrive/Models/RealRNN_1-3-2021_300Ep_Onlyphi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X72YH9S87cvW"
   },
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H.keys())\n",
    "# print(\"loss: \", H[\"loss\"])\n",
    "# print(\"mae: \", H[\"mae\"])\n",
    "# print(\"val_loss: \", H.history[\"val_loss\"])\n",
    "# print(\"val_mae: \", H.history[\"val_mae\"])\n",
    "\n",
    "lim = 0\n",
    "\n",
    "if len(H.keys()) > 4:\n",
    "  # fig, ax = plt.subplots(4,1,figsize=(5,20))\n",
    "  fig, ax = plt.subplots(3,1,figsize=(5,15))\n",
    "  fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "  ax[0].plot(H[\"loss\"][lim:])\n",
    "  # ax[0].plot(H.history[\"val_loss\"][lim:])\n",
    "  ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "  ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "  # ax[0].set_yscale(\"log\")\n",
    "  ax[0].legend([\"train\",\"val\"])\n",
    "  ax[0].grid(True)\n",
    "\n",
    "\n",
    "  ax[1].plot(H[\"mae\"][lim:])\n",
    "  # ax[1].plot(H.history[\"val_mae\"][lim:])\n",
    "  ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "  ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "  ax[1].legend([\"train\",\"val\"])\n",
    "  ax[1].grid(True)\n",
    "\n",
    "  ax[2].plot(H[\"q_pt\"][lim:])\n",
    "  ax[2].plot(H[\"phi\"][lim:])\n",
    "  ax[2].plot(H[\"tanl\"][lim:])\n",
    "  ax[2].plot(H[\"D\"][lim:])\n",
    "  ax[2].plot(H[\"z\"][lim:])\n",
    "  ax[2].set_title(\"data vs epoch\", fontsize=20)\n",
    "  ax[2].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[2].set_ylabel(\"data\", fontsize=15)\n",
    "  ax[2].legend([\"q_pt\",\"phi\",\"tanl\",\"D\",\"z\"])\n",
    "  # ax[2].legend([\"phi\",\"tanl\",\"D\",\"z\"])\n",
    "  # ax[2].legend([\"phi\",\"D\",\"z\"])\n",
    "  ax[2].grid(True)\n",
    "\n",
    "  # ax[3].plot(H.history[\"val_q_pt\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_phi\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_tanl\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_D\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_z\"][lim:])\n",
    "  # ax[3].set_title(\"data vs epoch\", fontsize=20)\n",
    "  # ax[3].set_xlabel(\"epoch\", fontsize=15)\n",
    "  # ax[3].set_ylabel(\"data\", fontsize=15)\n",
    "  # ax[3].legend([\"val_q_pt\",\"val_phi\",\"val_tanl\",\"val_D\",\"val_z\"])\n",
    "  # # ax[3].legend([\"val_phi\",\"val_tanl\",\"val_D\",\"val_z\"])\n",
    "  # # ax[3].legend([\"val_phi\",\"val_D\",\"val_z\"])\n",
    "  # ax[3].grid(True)\n",
    "\n",
    "else:\n",
    "  fig, ax = plt.subplots(2,1,figsize=(5,10))\n",
    "  fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "  ax[0].plot(H[\"loss\"][lim:])\n",
    "  # ax[0].plot(H.history[\"val_loss\"][lim:])\n",
    "  ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "  ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "  # ax[0].set_yscale(\"log\")\n",
    "  ax[0].legend([\"train\",\"val\"])\n",
    "  ax[0].grid(True)\n",
    "\n",
    "\n",
    "  ax[1].plot(H[\"mae\"][lim:])\n",
    "  # ax[1].plot(H.history[\"val_mae\"][lim:])\n",
    "  ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "  ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "  ax[1].legend([\"train\",\"val\"])\n",
    "  ax[1].grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "k6XSgSit7dE3",
    "outputId": "b3a1caaf-1b21-4348-bfe7-1315ccb39171"
   },
   "outputs": [],
   "source": [
    "print(H.history.keys())\n",
    "print(\"loss: \", H.history[\"loss\"])\n",
    "print(\"mae: \", H.history[\"mae\"])\n",
    "# print(\"val_loss: \", H.history[\"val_loss\"])\n",
    "# print(\"val_mae: \", H.history[\"val_mae\"])\n",
    "\n",
    "lim = 2\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(5,10))\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "ax[0].plot(H.history[\"loss\"][lim:])\n",
    "# ax[0].plot(H.history[\"val_loss\"][lim:])\n",
    "ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].legend([\"train\",\"val\"])\n",
    "ax[0].grid(True)\n",
    "\n",
    "\n",
    "ax[1].plot(H.history[\"mae\"][lim:])\n",
    "# ax[1].plot(H.history[\"val_mae\"][lim:])\n",
    "ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "ax[1].legend([\"train\",\"val\"])\n",
    "ax[1].grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UV GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][0].shape[0] # (event,hits,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for z in range(10):\n",
    "    col = 1\n",
    "    row = 2\n",
    "#     fig, ax = plt.subplots(row,col,figsize=(5*col,5*row))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(row, col, hspace=0, wspace=0)\n",
    "    ax = gs.subplots(sharex='col', sharey='row')\n",
    "    \n",
    "#     fig.subplots_adjust(hspace=0.5)\n",
    "    u_hits = []\n",
    "    v_hits = []\n",
    "    z_hits = []\n",
    "    for i in range(x_train[0][z].shape[0]):\n",
    "        u_hits.append(x_train[0][z][i][0])\n",
    "        v_hits.append(x_train[0][z][i][1])\n",
    "        z_hits.append(x_train[0][z][i][6])\n",
    "    ax[0].plot(z_hits,u_hits,\"o\")\n",
    "#     ax[0].x_label(\"z_hits\")\n",
    "#     ax[0].y_label(\"u_hits\")\n",
    "    ax[1].plot(z_hits,v_hits,\"o\")\n",
    "#     ax[1].x_label(\"z_hits\")\n",
    "#     ax[1].x_label(\"v_hits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOi6MC8u7swr"
   },
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqqb7Riq7tAY"
   },
   "outputs": [],
   "source": [
    "# Maybe copy over previous function and edit that?\n",
    "def graph(pred, true, diff):\n",
    "\n",
    "  values = [\"u\",\"v\",\"sin(v)\",\"cos(v)\",\"sin(u)\",\"cos(u)\",\"s\",\"ds\",\"wire\",\"glayer\",\"z\",\"time\",\"dE_amp\",\"q\"]\n",
    "  limits = [[\"todo\"]]\n",
    "\n",
    "  size = len(values)\n",
    "\n",
    "  fig, axs = plt.subplots(4,size,figsize=(size*5,20))\n",
    "  fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "\n",
    "  for i in range(size):\n",
    "    (mu, sigma) = norm.fit(diff[:,i])\n",
    "    print(\"data\" , values[i] ,\" |: mu: \", mu, \"sigma: \" , sigma)\n",
    "    _, bins, _ = axs[0,i].hist(diff[:,i], 20, density=True)\n",
    "    y = norm.pdf(bins, mu, sigma)\n",
    "    l = axs[0,i].plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "    axs[0,i].set_title(values[i] + ' diff')\n",
    "    axs[0,i].set_ylabel('freq')\n",
    "    axs[0,i].set_xlabel(values[i] + ' diff')\n",
    "\n",
    "  #--------------------------------------\n",
    "  # PREDICTED VS TRUE\n",
    "  #--------------------------------------\n",
    "    \n",
    "  for i in range(size):\n",
    "    axs[1,i].scatter(true[:,i],pred[:,i])\n",
    "    axs[1,i].grid(True)\n",
    "\n",
    "    axs[1,i].set_title(values[i] + ' (predicted vs true)')\n",
    "    axs[1,i].set_ylabel('pred ' + values[i])\n",
    "    axs[1,i].set_xlabel('true ' + values[i])\n",
    "\n",
    "    # axs[1,i].set_xlim(limits[i])\n",
    "    # axs[1,i].set_ylim(limits[i])\n",
    "    # axs[1,i].plot(limits[i],limits[i], color='b')\n",
    "\n",
    "  #--------------------------------------\n",
    "  # DIFFERENCE VS TRUE\n",
    "  #--------------------------------------\n",
    "\n",
    "  for i in range(size):\n",
    "    axs[2,i].scatter(true[:,i],diff[:,i])\n",
    "    l, r = axs[2,i].get_xlim()\n",
    "    axs[2,i].hlines(0, l, r)\n",
    "    axs[2,i].grid(True)\n",
    "\n",
    "    axs[2,i].set_title(values[i] + ' (difference vs true)')\n",
    "    axs[2,i].set_ylabel('diff ' + values[i])\n",
    "    axs[2,i].set_xlabel('true ' + values[i])\n",
    "\n",
    "  #--------------------------------------\n",
    "  # DIFFERENCE VS TRUE 2D HIST\n",
    "  #--------------------------------------\n",
    "\n",
    "  for i in range(size):\n",
    "    axs[3,i].hist2d(true[:,i],diff[:,i],bins=20)\n",
    "\n",
    "    axs[2,i].set_title(values[i] + ' (difference vs true)')\n",
    "    axs[2,i].set_ylabel('diff ' + values[i])\n",
    "    axs[2,i].set_xlabel('true ' + values[i])\n",
    "\n",
    "  fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHuUmXPCiXt9"
   },
   "outputs": [],
   "source": [
    "def gen_test_data(x_test, y_test, size=1000):\n",
    "  pred = model.predict(x_test)\n",
    "  diff = pred - y_test\n",
    "  return pred, y_test, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AMRhD6Wi7Xh"
   },
   "outputs": [],
   "source": [
    "graph(gen_test_data(x_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAUyMneo7Xj1"
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBsHjTgG7X2y"
   },
   "outputs": [],
   "source": [
    "# make test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWkYEQvFZ7HC"
   },
   "source": [
    "# Verification of proper data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqKxKcOQYEO4"
   },
   "source": [
    "## Using Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml3HHzoEaAhr"
   },
   "outputs": [],
   "source": [
    "aax, aay = next(train_gen)\n",
    "print(aax.shape)\n",
    "print(aay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gv72llYMaUYd"
   },
   "outputs": [],
   "source": [
    "print(\"x\",aax[0])\n",
    "print(\"y\",aay[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcwDKKLLe079"
   },
   "source": [
    "## Non Genenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlU3tRGpYxQV",
    "outputId": "a24ded2d-d1d0-4555-84a9-428edf5b2e7d"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  aax = x_train[i]\n",
    "  aay = y_train[i]\n",
    "  # print(aax.shape)\n",
    "  # print(aay.shape)\n",
    "  # print(\"x\",aax)\n",
    "  print(\"y\",aay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCpP2wsfdeGl"
   },
   "source": [
    "## Graphs of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAxLbw94GYzm"
   },
   "source": [
    "### filter_ignore\n",
    "\n",
    "Filters out large and small values and graphs them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiUKfbtfAoLm"
   },
   "outputs": [],
   "source": [
    "def filter_ignore(var,min=None,max=None,bins=25,ylog=False,xlog=False,cut=True):\n",
    "  list_ignore = []\n",
    "\n",
    "  print(\"--== {} ==--\\n\".format(var))\n",
    "\n",
    "  largest = 0\n",
    "  smallest = 0\n",
    "  for i in range(len(csv_train[var])):\n",
    "    if csv_train[var][i] > csv_train[var][largest]:\n",
    "      largest = i\n",
    "    if csv_train[var][i] < csv_train[var][smallest]:\n",
    "      smallest = i\n",
    "  print(\"largest value:  ({}, {:.3f})\".format(largest,csv_train[var][largest]))\n",
    "  print(\"smallest value: ({}, {:.3f})\".format(smallest,csv_train[var][smallest]))\n",
    "\n",
    "  print(\"\")\n",
    "\n",
    "  if min:\n",
    "    for i in range(len(csv_train[var])):\n",
    "      if csv_train[var][i] < min:\n",
    "        list_ignore.append(i)\n",
    "    print(\"min IDs to ignore for '{}':\".format(var))\n",
    "    print(csv_train[var][list_ignore])\n",
    "    print(\"\")\n",
    "  if max:\n",
    "    for i in range(len(csv_train[var])):\n",
    "      if csv_train[var][i] > max:\n",
    "        list_ignore.append(i)\n",
    "    print(\"max IDs to ignore for '{}':\".format(var))\n",
    "    print(csv_train[var][list_ignore])\n",
    "    print(\"\")\n",
    "  if min and max:\n",
    "    print(\"total IDs to ignore for '{}':\".format(var))\n",
    "    print(csv_train[var][list_ignore])\n",
    "    print(\"\")\n",
    "    plt.hist(csv_train[var],range=[min,max],bins=bins)\n",
    "  elif min:\n",
    "    plt.hist(csv_train[var],range=[min,csv_train[var][largest]],bins=bins)\n",
    "  elif max:\n",
    "    plt.hist(csv_train[var],range=[csv_train[var][smallest],max],bins=bins)\n",
    "  else:\n",
    "    plt.hist(csv_train[var],bins=bins)\n",
    "  \n",
    "  plt.title(var)\n",
    "  if cut:\n",
    "    plt.xlim(left=min,right=max)\n",
    "  if ylog:\n",
    "    plt.yscale(\"log\")\n",
    "  if xlog:\n",
    "    plt.xscale(\"log\")\n",
    "  plt.show()\n",
    "  return list_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "BwsJ0YIoBiew",
    "outputId": "962724f0-0845-4ab5-8b27-043de6744e44"
   },
   "outputs": [],
   "source": [
    "filter_ignore(\"q_over_pt\",min=-4000,bins=30,ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "2Wyjq07YGjBF",
    "outputId": "9a82db49-7e7e-49aa-8d4b-a0da738ec1f5"
   },
   "outputs": [],
   "source": [
    "filter_ignore(\"tanl\",max=1000,bins=25,ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xauTTOyrHPyT"
   },
   "outputs": [],
   "source": [
    "rms_ignore = filter_ignore(\"rms\",max=0.1,bins=25,ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "ERa-RZDbN6Hm",
    "outputId": "ac4577c9-f719-47d4-bc16-8fdbb7e413a5"
   },
   "outputs": [],
   "source": [
    "# 'q_over_pt', 'phi', 'tanl', 'D', 'z'\n",
    "# filter_ignore(\"D\", min=-200, ylog=True,bins=25)\n",
    "filter_ignore(\"z\",bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBO9wKCH2ePH"
   },
   "outputs": [],
   "source": [
    "csv_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc3WNfPaYwaL"
   },
   "source": [
    "### 1D Hist of all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "2VqlQxZRgTB7",
    "outputId": "2a5ce7d3-1665-4d71-80f5-5b7ed7ceb673"
   },
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"phi\"],bins=50) # -3 to 3, even distrib\n",
    "plt.title(\"phi\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"D\"],range=[-3000,80],bins=25) # -3000 to 50, but val in 65\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"D\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"z\"],bins=100)\n",
    "plt.title(\"z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TbqYK55L05mB",
    "outputId": "81dc2a8d-b572-4505-983a-8958a9bea8b6"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,1,figsize=(5,10))\n",
    "# fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.hist(csv_train[\"cov_00\"],range=[0,1e8],bins=25) # 0 to 1e13\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"cov_00\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"cov_01\"],bins=25) # -1e6 to over 1e5\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"cov_01\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"chisq\"],bins=25) # 0 to 200\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"chisq\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"Ndof\"],range=[0,44],bins=45) # ? this one weird 0 to ~43\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Ndof\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"rms\"],range=[0,0.1],bins=25) # \n",
    "# plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"rms\")\n",
    "plt.show()\n",
    "# ---\n",
    "# plt.hist(csv_train[\"t_start_cntr\"],bins=25) # -60 to ~50\n",
    "plt.hist(csv_train[csv_train[\"t_start_cntr_valid\"] == 1][\"t_start_cntr\"],bins=25) # -60 to ~50\n",
    "plt.title(\"t_start_cntr\")\n",
    "plt.show()\n",
    "\n",
    "# plt.hist(csv_train[\"t_tof\"],bins=25) # ~-120 to ~175\n",
    "plt.hist(csv_train[csv_train[\"t_tof_valid\"] == 1][\"t_tof\"],bins=25) # ~-120 to ~175\n",
    "plt.title(\"t_tof\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_bcal\"],bins=25) # ~-22 to 20\n",
    "plt.title(\"t_bcal\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_fcal\"],bins=25) # ~-100 to ~75\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"t_fcal\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"t_start_cntr_valid\"],bins=25) # a lot more 0s\n",
    "plt.title(\"t_start_cntr_valid\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_tof_valid\"],bins=25) # about 5050\n",
    "plt.title(\"t_tof_valid\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_bcal_valid\"],bins=25) # almost all 0s\n",
    "plt.title(\"t_bcal_valid\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_fcal_valid\"],bins=25) # almost all 0s\n",
    "plt.title(\"t_fcal_valid\")\n",
    "plt.show()\n",
    "# ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbzN70C9MCrQ"
   },
   "source": [
    "### 1D Hist of Hit1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VGzHLbKsLUZ9",
    "outputId": "0e1a0a14-8881-439d-c2f3-f0ec09006cc4"
   },
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"hit1_u\"],bins=25) # -42 to 42\n",
    "plt.title(\"hit1_u\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_v\"],bins=25) # -42 to 42\n",
    "plt.title(\"hit1_v\")\n",
    "plt.show()\n",
    "# plt.hist(csv_train[\"hit1_sinv\"],bins=25) # most are 0.96603 almost all are around that though\n",
    "# plt.title(\"hit1_sinv\")\n",
    "# plt.show()\n",
    "# plt.hist(csv_train[\"hit1_cosv\"],bins=25) # most -0.2585\n",
    "# plt.title(\"hit1_cosv\")\n",
    "# plt.show()\n",
    "# plt.hist(csv_train[\"hit1_sinu\"],bins=25) # most 0.96585\n",
    "# plt.title(\"hit1_sinu\")\n",
    "# plt.show()\n",
    "# plt.hist(csv_train[\"hit1_cosu\"],bins=25) # most 0.2591\n",
    "# plt.title(\"hit1_cosu\")\n",
    "# plt.show()\n",
    "plt.hist(csv_train[\"hit1_s\"],bins=25) # -42 to 42\n",
    "plt.title(\"hit1_s\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_ds\"],bins=25) # 0.01 to 0.04\n",
    "plt.title(\"hit1_ds\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_wire\"],bins=101,range=[0,100]) # 0 to 100\n",
    "plt.title(\"hit1_wire\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_glayer\"],bins=25,range=[0,26]) # 6 to 23\n",
    "plt.title(\"hit1_glayer\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_z\"],bins=25) # spaced out between 180 and 340\n",
    "plt.title(\"hit1_z\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_time\"],bins=25) # -75 to 270\n",
    "plt.title(\"hit1_time\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_dE_amp\"],bins=25) # 0 to 2e-7\n",
    "plt.title(\"hit1_dE_amp\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_q\"],bins=25) # 0 to 85\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"hit1_q\")\n",
    "plt.show()\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxIRSBXpYzU7"
   },
   "source": [
    "### 2D Scatters of various data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "8hgtNdVxY-4_",
    "outputId": "9e12924e-9cb0-492c-fcbb-8cbc7ed4680e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(csv_train[\"tanl\"],abs(csv_train[\"q_over_pt\"]),s=0.01) # a lot more 0s\n",
    "plt.title(\"q_over_pt vs tanl\")\n",
    "plt.xlabel(\"tanl\")\n",
    "plt.ylabel(\"q_over_pt\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "4pjOeJd85uWM",
    "outputId": "887b1312-0399-4223-ff5d-576875baa7e8"
   },
   "outputs": [],
   "source": [
    "# all create a plus sign\n",
    "plt.scatter(csv_train[\"t_start_cntr\"],csv_train[\"t_tof\"]) # a lot more 0s\n",
    "plt.title(\"t_tof vs t_start_cntr\")\n",
    "plt.xlabel(\"t_start_cntr\")\n",
    "plt.ylabel(\"t_tof\")\n",
    "plt.show()\n",
    "\n",
    "# plt.hist(csv_train[\"t_start_cntr\"],bins=25) # -60 to ~50\n",
    "# plt.hist(csv_train[\"t_tof\"],bins=25) # ~-120 to ~175\n",
    "# plt.hist(csv_train[\"t_bcal\"],bins=25) # ~-22 to 20\n",
    "# plt.hist(csv_train[\"t_fcal\"],bins=25) # ~-100 to ~75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "IFF2_7npOseE",
    "outputId": "8e8bec48-6610-41d1-8faa-64814bb75af9"
   },
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"hit1_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit2_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit3_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit4_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit5_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit6_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit10_glayer\"],bins=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdRImNvKZ0Fa"
   },
   "source": [
    "### 2D Scatters of various hit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mxK94YV2FM2"
   },
   "outputs": [],
   "source": [
    "# Oval\n",
    "plt.scatter(csv_train[\"hit1_u\"],csv_train[\"hit1_v\"]) # -3 to 3, even distrib\n",
    "plt.title(\"v vs u\")\n",
    "plt.xlabel(\"u\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()\n",
    "\n",
    "# like a flame\n",
    "plt.scatter(csv_train[\"hit1_s\"],csv_train[\"hit1_ds\"]) # -3 to 3, even distrib\n",
    "plt.title(\"ds vs s\")\n",
    "plt.xlabel(\"s\")\n",
    "plt.ylabel(\"ds\")\n",
    "plt.show()\n",
    "\n",
    "# hit1_wire, with single letters, forms an oval\n",
    "plt.scatter(csv_train[\"hit1_wire\"],csv_train[\"hit1_s\"]) # -3 to 3, even distrib\n",
    "plt.title(\"hit1_s vs hit1_wire\")\n",
    "plt.xlabel(\"hit1_wire\")\n",
    "plt.ylabel(\"hit1_s\")\n",
    "plt.show()\n",
    "\n",
    "# go up in steps\n",
    "plt.scatter(csv_train[\"hit1_glayer\"],csv_train[\"hit1_z\"]) # -3 to 3, even distrib\n",
    "plt.title(\"z vs glayer\")\n",
    "plt.xlabel(\"glayer\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.show()\n",
    "\n",
    "# 1:1\n",
    "plt.scatter(csv_train[\"hit1_q\"],csv_train[\"hit1_dE_amp\"]) # -3 to 3, even distrib\n",
    "plt.title(\"dE_amp vs q\")\n",
    "plt.xlabel(\"q\")\n",
    "plt.ylabel(\"dE_amp\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhNGqPbNQ8fX"
   },
   "outputs": [],
   "source": [
    "aax = \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dM6aySx8xO-"
   },
   "source": [
    "# Depricated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie8Rhqf765N5"
   },
   "source": [
    "## Non Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpJHFBHy74vp"
   },
   "outputs": [],
   "source": [
    "# --==Not in use?==--\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.8)\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "nInput = 10\n",
    "\n",
    "# inputs = keras.layers.Input((None,nInput))\n",
    "# print(\"train shape of one batch:\", x_train.shape[1:])\n",
    "\n",
    "# --==Set seed to get identical results==-- begin\n",
    "# from tensorflow.random import set_seed\n",
    "# np.random.seed(1)\n",
    "# set_seed(2)\n",
    "# --==Set seed to get identical results==-- end\n",
    "\n",
    "\n",
    "#--==Set Weights==--\n",
    "# loss_weights = [1/(sd**2)]\n",
    "# loss_weights = np.array(loss_weights)/sum(loss_weights)\n",
    "# model.compile(optimizer=optimizer, loss=\"mse\", loss_weights=loss_weights, metrics=[\"mae\"])\n",
    "\n",
    "inputs = keras.Input((None,nInput),ragged=True)\n",
    "\n",
    "# --==Choose model==--\n",
    "# x = model(inputs)\n",
    "# x = model_timeless(inputs)\n",
    "# x = RNNTime(inputs)\n",
    "x = RNNTimeless(inputs)\n",
    "# x = RNNTimeStateful(inputs)\n",
    "\n",
    "\n",
    "outs = {\n",
    "    \"q_pt\":Dense(1, name=\"q_pt\")(x),\n",
    "    \"phi\":Dense(1, name=\"phi\")(x),\n",
    "    \"tanl\":Dense(1, name=\"tanl\")(x),\n",
    "    \"D\":Dense(1, name=\"D\")(x),\n",
    "    \"z\":Dense(1, name=\"z\")(x)\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    \"q_pt\":y_train[:,0],\n",
    "    \"phi\":y_train[:,1],\n",
    "    \"tanl\":y_train[:,2],\n",
    "    \"D\":y_train[:,3],\n",
    "    \"z\":y_train[:,4]\n",
    "}\n",
    "\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=x, name=\"RNNModel\")\n",
    "# model = keras.Model(inputs=inputs, outputs=x, name=\"RNNModel\")\n",
    "model = keras.Model(inputs=inputs, outputs=outs, name=\"RNNModel\")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hw07sS4jFgJI"
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=50, mode='min', verbose=1, restore_best_weights=True)\n",
    "rag_x = x_train[0]\n",
    "H = model.fit(x=rag_x, y=y_dict, batch_size=64, epochs=100, verbose=1, callbacks=[es])\n",
    "\n",
    "# Overfit\n",
    "# es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=100, mode='min', verbose=1, restore_best_weights=True)\n",
    "# H = model.fit(x=x_train[:10], y=y_train[:10], batch_size=1, epochs=200, verbose=1, shuffle=True, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMcu1m3k7rHK"
   },
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUBj5VjBuyL9"
   },
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7-v4CJdyQk8",
    "outputId": "940df566-bd20-4356-a2cb-da3bcfaa5fd9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "\n",
    "  # print(y_pred)\n",
    "\n",
    "  y_pred_a = []\n",
    "  for k in y_pred.keys():\n",
    "    y_pred_a.append(np.squeeze(y_pred[k]))\n",
    "\n",
    "  y_pred = np.array(y_pred_a).astype(\"float64\")\n",
    "  y_pred = tf.transpose(y_pred, perm=(1,0))\n",
    "  # print(y_pred.shape)\n",
    "  print(y_pred)\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred dict shape of each is (batch, 1)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_loss = K.reshape(y_dot, (batch_size, 5))  # y_dot shape is now (batch,5)\n",
    "\n",
    "  y_dict = {\n",
    "      \"q_pt\":y_loss[:,0],\n",
    "      \"phi\":y_loss[:,1],\n",
    "      \"tanl\":y_loss[:,2],\n",
    "      \"D\":y_loss[:,3],\n",
    "      \"z\":y_loss[:,4],\n",
    "  }\n",
    "\n",
    "  # y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  # y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  # y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_dict\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = y_train[0]\n",
    "x_test = x_train[2][0:4]\n",
    "y_test = model.predict([x_train[0][0:4],x_train[1][0:4],x_train[2][0:4]])\n",
    "inconv_test = x_train[1][0:4]\n",
    "\n",
    "# for k in y_test.keys():\n",
    "#   y_test[k] = np.squeeze(y_test[k])\n",
    "# print(y_test)\n",
    "\n",
    "# print(y_test)\n",
    "# y_test_a = []\n",
    "# for k in y_test.keys():\n",
    "#   y_test_a.append(y_test[k])\n",
    "# y_test = np.squeeze(np.array(y_test_a))\n",
    "# print(y_test.shape)\n",
    "# print(y_test)\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "loss = K.eval(customLoss(x_test, y_test, inconv_test))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAP0kzRvu2hz"
   },
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7mcvkxuuweK",
    "outputId": "1197158f-904e-4103-f45a-2f015a71f639"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(q_pt_true, phi_true, tanl_true, D_true, z_true, q_pt_pred, phi_pred, tanl_pred, D_pred, z_pred, invcov):\n",
    "\n",
    "\n",
    "  y_pred = [q_pt_pred, phi_pred, tanl_pred, D_pred, z_pred]\n",
    "  # y_pred = np.array(y_pred).astype(\"float64\")\n",
    "  y_pred = tf.transpose(y_pred, perm=(1,0))\n",
    "  y_pred = tf.cast(y_pred, \"float64\")\n",
    "\n",
    "  y_true = [q_pt_true, phi_true, tanl_true, D_true, z_true]\n",
    "  # y_true = np.array(y_true).astype(\"float64\")\n",
    "  y_true = tf.transpose(y_true, perm=(1,0))\n",
    "  y_true = tf.cast(y_true, \"float64\")\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred dict shape of each is (batch, 1)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_loss = K.reshape(y_dot, (batch_size, 5))  # y_dot shape is now (batch,5)\n",
    "\n",
    "  y_dict = {\n",
    "      \"q_pt\":y_loss[:,0],\n",
    "      \"phi\":y_loss[:,1],\n",
    "      \"tanl\":y_loss[:,2],\n",
    "      \"D\":y_loss[:,3],\n",
    "      \"z\":y_loss[:,4],\n",
    "  }\n",
    "\n",
    "  # y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  # y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  # y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_dict\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = y_train[0]\n",
    "x_test = x_train[2][0:4]\n",
    "y_test = model.predict([x_train[0][0:4],x_train[1][0:4],x_train[2][0:4]])\n",
    "inconv_test = x_train[1][0:4]\n",
    "\n",
    "y_test_a = []\n",
    "for k in y_test.keys():\n",
    "  y_test_a.append(y_test[k])\n",
    "y_test = np.squeeze(np.array(y_test_a))\n",
    "y_test = np.swapaxes(y_test, 0, 1)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "loss = K.eval(customLoss(x_test[:,0],x_test[:,1],x_test[:,2],x_test[:,3],x_test[:,4], y_test[:,0], y_test[:,1],y_test[:,2],y_test[:,3],y_test[:,4], inconv_test))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kuUpxAuz1sz"
   },
   "source": [
    "### V4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRUvQVjHAD2U"
   },
   "source": [
    "So, we have the prediction and true vector\n",
    "\n",
    "$$\n",
    "y_{pred}=\n",
    "\\begin{bmatrix}\n",
    "q\\_pt \\\\ phi \\\\ tanl \\\\ D \\\\ z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We have the inverse covariance matrix, we'll label it $C^{-1}$:\n",
    "\n",
    "and $y_p = y_{predict}$\n",
    "\n",
    "$$\n",
    "C^{-1} = \n",
    "\\begin{bmatrix}\n",
    "qq & qp & qt & qd & qz \\\\\n",
    "qp & pp & pt & pd & pz \\\\\n",
    "qt & pt & tt & td & tz \\\\\n",
    "qd & pd & td & dd & dz \\\\\n",
    "qz & pz & tz & dz & zz \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus, the formula before was:\n",
    "\n",
    "$$\n",
    "loss = C^{-1} \\cdot \\vec{y_p}  \\cdot \\vec{y_p}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  y_{dot} =\n",
    "  \\begin{bmatrix}\n",
    "    qq & qp & qt & qd & qz \\\\\n",
    "    qp & pp & pt & pd & pz \\\\\n",
    "    qt & pt & tt & td & tz \\\\\n",
    "    qd & pd & td & dd & dz \\\\\n",
    "    qz & pz & tz & dz & zz \n",
    "  \\end{bmatrix} \n",
    "  \\cdot\n",
    "  \\begin{bmatrix}\n",
    "    q\\_pt \\\\ phi \\\\ tanl \\\\ D \\\\ z\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  y_{dot} = \n",
    "  \\begin{bmatrix}\n",
    "    qq*q\\_pt + qp*phi + qt*tanl + qd*D + qz*z \\\\\n",
    "    qp*q\\_pt + pp*phi + pt*tanl + pd*D + pz*z \\\\\n",
    "    qt*q\\_pt + pt*phi + tt*tanl + td*D + tz*z \\\\\n",
    "    qd*q\\_pt + pd*phi + td*tanl + dd*D + dz*z \\\\\n",
    "    qz*q\\_pt + dz*phi + tz*tanl + pz*D + zz*z\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Now, working on the output split for each variable, im looking for ways to seperate the variables after that operation.\n",
    "So maybe just sum the q_pt column of the matrix and multiply by q_pt?\n",
    "\n",
    "Maybe this would work? :\n",
    "\n",
    "$$\n",
    "loss_{q\\_pt} =  y_p^{q\\_pt} * \\sum_{i=0}^{4} C^{-1}_{qi}\n",
    "$$\n",
    "\n",
    "Where $C^{-1}_q$ is one row or column of the matrix of that variable\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8shIh2axz1g_",
    "outputId": "bbc9620f-ee91-4ed5-a02c-8e29e698e46b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "  # print(y_pred)\n",
    "\n",
    "  # Theoretically:\n",
    "  # K.dot(invcov[0,:] * q_pt,q_pt)    # ?\n",
    "  \n",
    "\n",
    "\n",
    "  y_pred_a = []\n",
    "  for k in y_pred.keys():\n",
    "    y_pred_a.append(np.squeeze(y_pred[k]))\n",
    "\n",
    "  y_pred = np.array(y_pred_a).astype(\"float64\")\n",
    "  y_pred = tf.transpose(y_pred, perm=(1,0))\n",
    "  # print(y_pred.shape)\n",
    "  print(y_pred)\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred dict shape of each is (batch, 1)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_loss = K.reshape(y_dot, (batch_size, 5))  # y_dot shape is now (batch,5)\n",
    "\n",
    "  y_dict = {\n",
    "      \"q_pt\":y_loss[:,0],\n",
    "      \"phi\":y_loss[:,1],\n",
    "      \"tanl\":y_loss[:,2],\n",
    "      \"D\":y_loss[:,3],\n",
    "      \"z\":y_loss[:,4],\n",
    "  }\n",
    "\n",
    "  # y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  # y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  # y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_dict\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = y_train[0]\n",
    "x_test = x_train[2][0:4]\n",
    "y_test = model.predict([x_train[0][0:4],x_train[1][0:4],x_train[2][0:4]])\n",
    "inconv_test = x_train[1][0:4]\n",
    "\n",
    "# for k in y_test.keys():\n",
    "#   y_test[k] = np.squeeze(y_test[k])\n",
    "# print(y_test)\n",
    "\n",
    "# print(y_test)\n",
    "# y_test_a = []\n",
    "# for k in y_test.keys():\n",
    "#   y_test_a.append(y_test[k])\n",
    "# y_test = np.squeeze(np.array(y_test_a))\n",
    "# print(y_test.shape)\n",
    "# print(y_test)\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "loss = K.eval(customLoss(x_test, y_test, inconv_test))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7htvZHbENgC7"
   },
   "source": [
    "### V5 unedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK6jqei9Nf5W"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  # y_dict = {\n",
    "  #     \"q_pt\":y_diff[0]*y_diff[0],\n",
    "  #     \"phi\":y_diff[0]*y_diff[0]\n",
    "  # }\n",
    "  # y_diff[0] / invcov[0][0]\n",
    "  return y_loss\n",
    "\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = x_train[2][0]\n",
    "# y_test = model.predict([x_train[0][0:1],x_train[1][0:1],x_train[2][0:1]])\n",
    "# y_test = np.squeeze(y_test)\n",
    "# inconv_test = x_train[1][0]\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "# # print('loss shape: '    + str(loss.shape)    )\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4XBVGilP4tc"
   },
   "source": [
    "### V6 New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsGirPS0P4jb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "def customLoss(m_invcov):\n",
    "  def customLoss_fn(y_true, y_pred):\n",
    "    batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "    y_pred = tf.cast(K.reshape(y_pred, (batch_size, 5,1)),\"float64\") # y_pred  shape is now (batch, 5,1)\n",
    "    y_true = tf.cast(K.reshape(y_true, (batch_size, 5,1)),\"float64\") # y_state shape is now (batch, 5,1)\n",
    "    invcov = tf.cast(K.reshape(m_invcov, (batch_size, 5,5)),\"float64\") # invcov  shape is now (batch, 5,5)\n",
    "    \n",
    "    # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "    invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "    \n",
    "    # Difference between prediction and true state vectors\n",
    "    y_diff = y_pred - y_true\n",
    "\n",
    "    # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "    y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "    y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "    y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "    y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "    return y_loss\n",
    "  return customLoss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkuUUNJWjM_i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "\n",
    "  y_pred = tf.cast(K.reshape(y_pred, (batch_size, 5,1)),\"float64\") # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = tf.cast(K.reshape(y_true, (batch_size, 5,1)),\"float64\") # y_state shape is now (batch, 5,1)\n",
    "  invcov = tf.cast(K.reshape(invcov, (batch_size, 5,5)),\"float64\") # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqNp5hG98yPr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DBknRRcl6LMm"
   ],
   "name": "CopyOfRNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
